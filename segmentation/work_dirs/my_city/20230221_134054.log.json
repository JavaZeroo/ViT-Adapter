{"env_info": "sys.platform: linux\nPython: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\nCUDA available: True\nGPU 0: NVIDIA A100-PCIE-40GB\nCUDA_HOME: /usr/local/cuda\nNVCC: Build cuda_11.1.TC455_06.29190527_0\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.9.0+cu111\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.10.0+cu111\nOpenCV: 4.6.0\nMMCV: 1.4.2\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.1\nMMSegmentation: 0.20.2+a1b84a3", "seed": 85636677, "exp_name": "my_city.py", "mmseg_version": "0.20.2+a1b84a3", "config": "num_things_classes = 0\nnum_stuff_classes = 16\nnum_classes = 16\nnorm_cfg = dict(type='SyncBN', requires_grad=True)\nmodel = dict(\n    type='EncoderDecoderMask2FormerAug',\n    pretrained='pretrained/beit_large_patch16_224_pt22k_ft22k.pth',\n    backbone=dict(\n        type='BEiTAdapter',\n        patch_size=16,\n        embed_dim=1024,\n        depth=24,\n        num_heads=16,\n        mlp_ratio=4,\n        qkv_bias=True,\n        use_abs_pos_emb=False,\n        use_rel_pos_bias=True,\n        img_size=896,\n        init_values=1e-06,\n        drop_path_rate=0.3,\n        conv_inplane=64,\n        n_points=4,\n        deform_num_heads=16,\n        cffn_ratio=0.25,\n        deform_ratio=0.5,\n        with_cp=True,\n        interaction_indexes=[[0, 5], [6, 11], [12, 17], [18, 23]],\n        pretrained='pretrained/beit_large_patch16_224_pt22k_ft22k.pth'),\n    decode_head=dict(\n        type='Mask2FormerHead',\n        in_channels=[1024, 1024, 1024, 1024],\n        feat_channels=1024,\n        out_channels=1024,\n        in_index=[0, 1, 2, 3],\n        num_things_classes=0,\n        num_stuff_classes=16,\n        num_queries=100,\n        num_transformer_feat_level=3,\n        pixel_decoder=dict(\n            type='MSDeformAttnPixelDecoder',\n            num_outs=3,\n            norm_cfg=dict(type='GN', num_groups=32),\n            act_cfg=dict(type='ReLU'),\n            encoder=dict(\n                type='DetrTransformerEncoder',\n                num_layers=6,\n                transformerlayers=dict(\n                    type='BaseTransformerLayer',\n                    attn_cfgs=dict(\n                        type='MultiScaleDeformableAttention',\n                        embed_dims=1024,\n                        num_heads=32,\n                        num_levels=3,\n                        num_points=4,\n                        im2col_step=64,\n                        dropout=0.0,\n                        batch_first=False,\n                        norm_cfg=None,\n                        init_cfg=None),\n                    ffn_cfgs=dict(\n                        type='FFN',\n                        embed_dims=1024,\n                        feedforward_channels=4096,\n                        num_fcs=2,\n                        ffn_drop=0.0,\n                        act_cfg=dict(type='ReLU', inplace=True),\n                        with_cp=True),\n                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),\n                init_cfg=None),\n            positional_encoding=dict(\n                type='SinePositionalEncoding', num_feats=512, normalize=True),\n            init_cfg=None),\n        enforce_decoder_input_project=False,\n        positional_encoding=dict(\n            type='SinePositionalEncoding', num_feats=512, normalize=True),\n        transformer_decoder=dict(\n            type='DetrTransformerDecoder',\n            return_intermediate=True,\n            num_layers=9,\n            transformerlayers=dict(\n                type='DetrTransformerDecoderLayer',\n                attn_cfgs=dict(\n                    type='MultiheadAttention',\n                    embed_dims=1024,\n                    num_heads=32,\n                    attn_drop=0.0,\n                    proj_drop=0.0,\n                    dropout_layer=None,\n                    batch_first=False),\n                ffn_cfgs=dict(\n                    embed_dims=1024,\n                    feedforward_channels=4096,\n                    num_fcs=2,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    ffn_drop=0.0,\n                    dropout_layer=None,\n                    add_identity=True,\n                    with_cp=True),\n                feedforward_channels=4096,\n                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',\n                                 'ffn', 'norm')),\n            init_cfg=None),\n        loss_cls=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=False,\n            loss_weight=2.0,\n            reduction='mean',\n            class_weight=[\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 0.1\n            ]),\n        loss_mask=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=True,\n            reduction='mean',\n            loss_weight=5.0),\n        loss_dice=dict(\n            type='DiceLoss',\n            use_sigmoid=True,\n            activate=True,\n            reduction='mean',\n            naive_dice=True,\n            eps=1.0,\n            loss_weight=5.0),\n        train_cfg=dict(\n            num_points=12544,\n            oversample_ratio=3.0,\n            importance_sample_ratio=0.75,\n            assigner=dict(\n                type='MaskHungarianAssigner',\n                cls_cost=dict(type='ClassificationCost', weight=2.0),\n                mask_cost=dict(\n                    type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n                dice_cost=dict(\n                    type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n            sampler=dict(type='MaskPseudoSampler')),\n        test_cfg=dict(\n            panoptic_on=True,\n            semantic_on=False,\n            instance_on=True,\n            max_per_image=100,\n            iou_thr=0.8,\n            filter_low_score=True,\n            mode='slide',\n            crop_size=(896, 896),\n            stride=(512, 512))),\n    train_cfg=dict(\n        num_points=12544,\n        oversample_ratio=3.0,\n        importance_sample_ratio=0.75,\n        assigner=dict(\n            type='MaskHungarianAssigner',\n            cls_cost=dict(type='ClassificationCost', weight=2.0),\n            mask_cost=dict(\n                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n            dice_cost=dict(\n                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n        sampler=dict(type='MaskPseudoSampler')),\n    test_cfg=dict(\n        panoptic_on=True,\n        semantic_on=False,\n        instance_on=True,\n        max_per_image=100,\n        iou_thr=0.8,\n        filter_low_score=True,\n        mode='slide',\n        crop_size=(896, 896),\n        stride=(512, 512)),\n    init_cfg=None)\ndataset_type = 'MyDataset'\ndata_root = '/root/autodl-tmp/data'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ncrop_size = (896, 896)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations'),\n    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n    dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),\n    dict(type='RandomFlip', prob=0.5),\n    dict(type='PhotoMetricDistortion'),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),\n    dict(type='ToMask'),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(2048, 1024),\n        img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n        flip=True,\n        transforms=[\n            dict(\n                type='SETR_Resize',\n                keep_ratio=True,\n                crop_size=(896, 896),\n                setr_multi_scale=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=1,\n    train=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/train',\n        ann_dir='annotations/train',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations'),\n            dict(\n                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n            dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),\n            dict(type='RandomFlip', prob=0.5),\n            dict(type='PhotoMetricDistortion'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),\n            dict(type='ToMask'),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n        ]),\n    val=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/val',\n        ann_dir='annotations/val',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2048, 1024),\n                img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n                flip=True,\n                transforms=[\n                    dict(\n                        type='SETR_Resize',\n                        keep_ratio=True,\n                        crop_size=(896, 896),\n                        setr_multi_scale=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/val',\n        ann_dir='annotations/val',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2048, 1024),\n                img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n                flip=True,\n                transforms=[\n                    dict(\n                        type='SETR_Resize',\n                        keep_ratio=True,\n                        crop_size=(896, 896),\n                        setr_multi_scale=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nlog_config = dict(\n    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'pretrained/mask2former_beit_adapter_large_896_80k_cityscapes.pth.tar'\nresume_from = None\nworkflow = [('train', 1)]\ncudnn_benchmark = True\noptimizer = dict(\n    type='AdamW',\n    lr=2e-05,\n    betas=(0.9, 0.999),\n    weight_decay=0.05,\n    constructor='LayerDecayOptimizerConstructor',\n    paramwise_cfg=dict(num_layers=24, layer_decay_rate=0.9))\noptimizer_config = dict()\nlr_config = dict(\n    policy='poly',\n    warmup='linear',\n    warmup_iters=1500,\n    warmup_ratio=1e-06,\n    power=1.0,\n    min_lr=0.0,\n    by_epoch=False)\nrunner = dict(type='IterBasedRunner', max_iters=80000)\ncheckpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)\nevaluation = dict(\n    interval=1000, metric='mIoU', pre_eval=True, save_best='mIoU')\npretrained = 'pretrained/beit_large_patch16_224_pt22k_ft22k.pth'\nwork_dir = './work_dirs/my_city'\ngpu_ids = range(0, 1)\nauto_resume = False\nseed = 85636677\n", "CLASSES": ["WATER", "ASPHALT", "GRASS", "HUMAN", "ANIMAL", "HIGH_VEGETATION", "GROUND_VEHICLE", "FACADE", "WIRE", "GARDEN_FURNITURE", "CONCRETE", "ROOF", "GRAVEL", "SOIL", "PRIMEAIR_PATTERN", "SNOW"], "PALETTE": [[148, 218, 255], [85, 85, 85], [200, 219, 190], [166, 133, 226], [255, 171, 225], [40, 150, 114], [234, 144, 133], [89, 82, 96], [255, 255, 0], [110, 87, 121], [205, 201, 195], [212, 80, 121], [159, 135, 114], [102, 90, 72], [255, 255, 102], [251, 247, 240]], "hook_msgs": {}}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 31487, "data_time": 0.02896, "decode.loss_cls": 5.94283, "decode.loss_mask": 2.22111, "decode.loss_dice": 2.63135, "decode.d0.loss_cls": 5.94076, "decode.d0.loss_mask": 2.26545, "decode.d0.loss_dice": 3.0681, "decode.d1.loss_cls": 6.2277, "decode.d1.loss_mask": 2.28516, "decode.d1.loss_dice": 2.73881, "decode.d2.loss_cls": 5.90485, "decode.d2.loss_mask": 2.19735, "decode.d2.loss_dice": 2.68838, "decode.d3.loss_cls": 5.85997, "decode.d3.loss_mask": 2.17728, "decode.d3.loss_dice": 2.61803, "decode.d4.loss_cls": 6.1592, "decode.d4.loss_mask": 2.20567, "decode.d4.loss_dice": 2.62038, "decode.d5.loss_cls": 6.34865, "decode.d5.loss_mask": 2.13502, "decode.d5.loss_dice": 2.6314, "decode.d6.loss_cls": 6.50195, "decode.d6.loss_mask": 2.17396, "decode.d6.loss_dice": 2.63891, "decode.d7.loss_cls": 6.39227, "decode.d7.loss_mask": 2.21109, "decode.d7.loss_dice": 2.63336, "decode.d8.loss_cls": 6.21355, "decode.d8.loss_mask": 2.20266, "decode.d8.loss_dice": 2.62573, "loss": 110.4609, "time": 2.83202}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.0, "memory": 31487, "data_time": 0.01852, "decode.loss_cls": 4.84588, "decode.loss_mask": 1.88315, "decode.loss_dice": 2.56573, "decode.d0.loss_cls": 5.98303, "decode.d0.loss_mask": 2.1011, "decode.d0.loss_dice": 3.02164, "decode.d1.loss_cls": 5.66092, "decode.d1.loss_mask": 1.95213, "decode.d1.loss_dice": 2.6836, "decode.d2.loss_cls": 5.13073, "decode.d2.loss_mask": 1.86657, "decode.d2.loss_dice": 2.61869, "decode.d3.loss_cls": 4.90332, "decode.d3.loss_mask": 1.82991, "decode.d3.loss_dice": 2.59682, "decode.d4.loss_cls": 5.0499, "decode.d4.loss_mask": 1.88515, "decode.d4.loss_dice": 2.58132, "decode.d5.loss_cls": 5.23266, "decode.d5.loss_mask": 1.8622, "decode.d5.loss_dice": 2.56127, "decode.d6.loss_cls": 5.21105, "decode.d6.loss_mask": 1.83462, "decode.d6.loss_dice": 2.56703, "decode.d7.loss_cls": 5.09788, "decode.d7.loss_mask": 1.83572, "decode.d7.loss_dice": 2.56839, "decode.d8.loss_cls": 5.0041, "decode.d8.loss_mask": 1.86273, "decode.d8.loss_dice": 2.57135, "loss": 97.36859, "time": 2.7228}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.0, "memory": 31487, "data_time": 0.01793, "decode.loss_cls": 3.7554, "decode.loss_mask": 1.46972, "decode.loss_dice": 2.23967, "decode.d0.loss_cls": 5.98909, "decode.d0.loss_mask": 1.85321, "decode.d0.loss_dice": 2.72815, "decode.d1.loss_cls": 4.68877, "decode.d1.loss_mask": 1.61252, "decode.d1.loss_dice": 2.41818, "decode.d2.loss_cls": 4.1329, "decode.d2.loss_mask": 1.48498, "decode.d2.loss_dice": 2.33255, "decode.d3.loss_cls": 3.94169, "decode.d3.loss_mask": 1.43236, "decode.d3.loss_dice": 2.26967, "decode.d4.loss_cls": 3.97332, "decode.d4.loss_mask": 1.45962, "decode.d4.loss_dice": 2.25188, "decode.d5.loss_cls": 3.95873, "decode.d5.loss_mask": 1.45108, "decode.d5.loss_dice": 2.24262, "decode.d6.loss_cls": 3.90939, "decode.d6.loss_mask": 1.4318, "decode.d6.loss_dice": 2.23556, "decode.d7.loss_cls": 3.86236, "decode.d7.loss_mask": 1.44548, "decode.d7.loss_dice": 2.24575, "decode.d8.loss_cls": 3.84209, "decode.d8.loss_mask": 1.43377, "decode.d8.loss_dice": 2.21996, "loss": 80.31226, "time": 2.72544}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.0, "memory": 31487, "data_time": 0.01861, "decode.loss_cls": 3.53921, "decode.loss_mask": 1.26802, "decode.loss_dice": 2.02157, "decode.d0.loss_cls": 6.01109, "decode.d0.loss_mask": 1.78978, "decode.d0.loss_dice": 2.54258, "decode.d1.loss_cls": 4.06373, "decode.d1.loss_mask": 1.46306, "decode.d1.loss_dice": 2.2549, "decode.d2.loss_cls": 3.77691, "decode.d2.loss_mask": 1.34066, "decode.d2.loss_dice": 2.16915, "decode.d3.loss_cls": 3.6863, "decode.d3.loss_mask": 1.2919, "decode.d3.loss_dice": 2.09505, "decode.d4.loss_cls": 3.71114, "decode.d4.loss_mask": 1.27653, "decode.d4.loss_dice": 2.07457, "decode.d5.loss_cls": 3.66116, "decode.d5.loss_mask": 1.27669, "decode.d5.loss_dice": 2.06864, "decode.d6.loss_cls": 3.60424, "decode.d6.loss_mask": 1.27704, "decode.d6.loss_dice": 2.03342, "decode.d7.loss_cls": 3.61816, "decode.d7.loss_mask": 1.26751, "decode.d7.loss_dice": 2.02961, "decode.d8.loss_cls": 3.58968, "decode.d8.loss_mask": 1.26755, "decode.d8.loss_dice": 2.00804, "loss": 74.07788, "time": 2.72642}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.0, "memory": 31487, "data_time": 0.01942, "decode.loss_cls": 3.41368, "decode.loss_mask": 1.20391, "decode.loss_dice": 2.04855, "decode.d0.loss_cls": 5.98962, "decode.d0.loss_mask": 1.7113, "decode.d0.loss_dice": 2.55991, "decode.d1.loss_cls": 3.92864, "decode.d1.loss_mask": 1.37355, "decode.d1.loss_dice": 2.34277, "decode.d2.loss_cls": 3.70185, "decode.d2.loss_mask": 1.24729, "decode.d2.loss_dice": 2.20001, "decode.d3.loss_cls": 3.55864, "decode.d3.loss_mask": 1.22098, "decode.d3.loss_dice": 2.11566, "decode.d4.loss_cls": 3.55446, "decode.d4.loss_mask": 1.20262, "decode.d4.loss_dice": 2.11399, "decode.d5.loss_cls": 3.55478, "decode.d5.loss_mask": 1.21167, "decode.d5.loss_dice": 2.09324, "decode.d6.loss_cls": 3.50542, "decode.d6.loss_mask": 1.18749, "decode.d6.loss_dice": 2.0765, "decode.d7.loss_cls": 3.48639, "decode.d7.loss_mask": 1.18675, "decode.d7.loss_dice": 2.07884, "decode.d8.loss_cls": 3.46361, "decode.d8.loss_mask": 1.20788, "decode.d8.loss_dice": 2.05678, "loss": 72.59675, "time": 2.73027}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.0, "memory": 31487, "data_time": 0.01861, "decode.loss_cls": 3.00736, "decode.loss_mask": 1.18148, "decode.loss_dice": 1.99257, "decode.d0.loss_cls": 5.9974, "decode.d0.loss_mask": 1.64376, "decode.d0.loss_dice": 2.5284, "decode.d1.loss_cls": 3.59092, "decode.d1.loss_mask": 1.2947, "decode.d1.loss_dice": 2.30939, "decode.d2.loss_cls": 3.34999, "decode.d2.loss_mask": 1.19755, "decode.d2.loss_dice": 2.1749, "decode.d3.loss_cls": 3.13859, "decode.d3.loss_mask": 1.16127, "decode.d3.loss_dice": 2.05774, "decode.d4.loss_cls": 3.13319, "decode.d4.loss_mask": 1.17134, "decode.d4.loss_dice": 2.04797, "decode.d5.loss_cls": 3.12022, "decode.d5.loss_mask": 1.19558, "decode.d5.loss_dice": 2.00687, "decode.d6.loss_cls": 3.06467, "decode.d6.loss_mask": 1.1754, "decode.d6.loss_dice": 2.0093, "decode.d7.loss_cls": 3.05891, "decode.d7.loss_mask": 1.18991, "decode.d7.loss_dice": 2.03104, "decode.d8.loss_cls": 3.02318, "decode.d8.loss_mask": 1.17642, "decode.d8.loss_dice": 2.00974, "loss": 68.03975, "time": 2.7296}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.0, "memory": 31487, "data_time": 0.01833, "decode.loss_cls": 2.77339, "decode.loss_mask": 1.11746, "decode.loss_dice": 1.86498, "decode.d0.loss_cls": 5.99378, "decode.d0.loss_mask": 1.52878, "decode.d0.loss_dice": 2.3604, "decode.d1.loss_cls": 3.49959, "decode.d1.loss_mask": 1.20855, "decode.d1.loss_dice": 2.12092, "decode.d2.loss_cls": 3.14487, "decode.d2.loss_mask": 1.13581, "decode.d2.loss_dice": 1.98225, "decode.d3.loss_cls": 2.90013, "decode.d3.loss_mask": 1.12172, "decode.d3.loss_dice": 1.91396, "decode.d4.loss_cls": 2.86909, "decode.d4.loss_mask": 1.11198, "decode.d4.loss_dice": 1.90331, "decode.d5.loss_cls": 2.87987, "decode.d5.loss_mask": 1.12813, "decode.d5.loss_dice": 1.87739, "decode.d6.loss_cls": 2.80901, "decode.d6.loss_mask": 1.10198, "decode.d6.loss_dice": 1.86504, "decode.d7.loss_cls": 2.77926, "decode.d7.loss_mask": 1.12444, "decode.d7.loss_dice": 1.85543, "decode.d8.loss_cls": 2.77297, "decode.d8.loss_mask": 1.11802, "decode.d8.loss_dice": 1.86538, "loss": 63.72785, "time": 2.72796}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.0, "memory": 31487, "data_time": 0.01868, "decode.loss_cls": 2.38982, "decode.loss_mask": 1.06065, "decode.loss_dice": 1.75674, "decode.d0.loss_cls": 6.02608, "decode.d0.loss_mask": 1.47346, "decode.d0.loss_dice": 2.25977, "decode.d1.loss_cls": 3.26795, "decode.d1.loss_mask": 1.15336, "decode.d1.loss_dice": 2.00316, "decode.d2.loss_cls": 2.79881, "decode.d2.loss_mask": 1.08724, "decode.d2.loss_dice": 1.85664, "decode.d3.loss_cls": 2.51593, "decode.d3.loss_mask": 1.0449, "decode.d3.loss_dice": 1.77249, "decode.d4.loss_cls": 2.46661, "decode.d4.loss_mask": 1.06435, "decode.d4.loss_dice": 1.78777, "decode.d5.loss_cls": 2.4558, "decode.d5.loss_mask": 1.07425, "decode.d5.loss_dice": 1.76058, "decode.d6.loss_cls": 2.4059, "decode.d6.loss_mask": 1.05006, "decode.d6.loss_dice": 1.75214, "decode.d7.loss_cls": 2.38553, "decode.d7.loss_mask": 1.06666, "decode.d7.loss_dice": 1.74581, "decode.d8.loss_cls": 2.3613, "decode.d8.loss_mask": 1.06928, "decode.d8.loss_dice": 1.74789, "loss": 58.66091, "time": 2.73154}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.0, "memory": 31487, "data_time": 0.01995, "decode.loss_cls": 2.24116, "decode.loss_mask": 1.05139, "decode.loss_dice": 1.70957, "decode.d0.loss_cls": 5.99767, "decode.d0.loss_mask": 1.35739, "decode.d0.loss_dice": 2.20779, "decode.d1.loss_cls": 3.02603, "decode.d1.loss_mask": 1.10613, "decode.d1.loss_dice": 1.94026, "decode.d2.loss_cls": 2.52348, "decode.d2.loss_mask": 1.08654, "decode.d2.loss_dice": 1.79661, "decode.d3.loss_cls": 2.29227, "decode.d3.loss_mask": 1.06552, "decode.d3.loss_dice": 1.74782, "decode.d4.loss_cls": 2.23608, "decode.d4.loss_mask": 1.05539, "decode.d4.loss_dice": 1.72051, "decode.d5.loss_cls": 2.25155, "decode.d5.loss_mask": 1.06846, "decode.d5.loss_dice": 1.72138, "decode.d6.loss_cls": 2.22286, "decode.d6.loss_mask": 1.04554, "decode.d6.loss_dice": 1.72709, "decode.d7.loss_cls": 2.22658, "decode.d7.loss_mask": 1.04985, "decode.d7.loss_dice": 1.70045, "decode.d8.loss_cls": 2.21206, "decode.d8.loss_mask": 1.05063, "decode.d8.loss_dice": 1.71241, "loss": 56.15049, "time": 2.74256}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.0, "memory": 31487, "data_time": 0.02034, "decode.loss_cls": 1.9287, "decode.loss_mask": 1.0652, "decode.loss_dice": 1.68791, "decode.d0.loss_cls": 5.97878, "decode.d0.loss_mask": 1.29407, "decode.d0.loss_dice": 2.15589, "decode.d1.loss_cls": 2.77302, "decode.d1.loss_mask": 1.0681, "decode.d1.loss_dice": 1.88672, "decode.d2.loss_cls": 2.19889, "decode.d2.loss_mask": 1.08134, "decode.d2.loss_dice": 1.76756, "decode.d3.loss_cls": 1.97006, "decode.d3.loss_mask": 1.06656, "decode.d3.loss_dice": 1.72443, "decode.d4.loss_cls": 1.93363, "decode.d4.loss_mask": 1.06728, "decode.d4.loss_dice": 1.71495, "decode.d5.loss_cls": 1.92769, "decode.d5.loss_mask": 1.06805, "decode.d5.loss_dice": 1.69268, "decode.d6.loss_cls": 1.90631, "decode.d6.loss_mask": 1.06656, "decode.d6.loss_dice": 1.70581, "decode.d7.loss_cls": 1.89813, "decode.d7.loss_mask": 1.06956, "decode.d7.loss_dice": 1.70891, "decode.d8.loss_cls": 1.89498, "decode.d8.loss_mask": 1.06552, "decode.d8.loss_dice": 1.70578, "loss": 53.07305, "time": 2.74378}
{"mode": "train", "epoch": 1, "iter": 550, "lr": 0.0, "memory": 31487, "data_time": 0.02295, "decode.loss_cls": 1.63619, "decode.loss_mask": 0.94824, "decode.loss_dice": 1.65515, "decode.d0.loss_cls": 6.00896, "decode.d0.loss_mask": 1.13326, "decode.d0.loss_dice": 2.05204, "decode.d1.loss_cls": 2.44802, "decode.d1.loss_mask": 0.99206, "decode.d1.loss_dice": 1.78827, "decode.d2.loss_cls": 1.90771, "decode.d2.loss_mask": 0.9792, "decode.d2.loss_dice": 1.68357, "decode.d3.loss_cls": 1.70094, "decode.d3.loss_mask": 0.95313, "decode.d3.loss_dice": 1.67144, "decode.d4.loss_cls": 1.65709, "decode.d4.loss_mask": 0.95049, "decode.d4.loss_dice": 1.6517, "decode.d5.loss_cls": 1.66377, "decode.d5.loss_mask": 0.95512, "decode.d5.loss_dice": 1.63349, "decode.d6.loss_cls": 1.65181, "decode.d6.loss_mask": 0.95779, "decode.d6.loss_dice": 1.64613, "decode.d7.loss_cls": 1.62514, "decode.d7.loss_mask": 0.95796, "decode.d7.loss_dice": 1.63278, "decode.d8.loss_cls": 1.61683, "decode.d8.loss_mask": 0.95829, "decode.d8.loss_dice": 1.64098, "loss": 48.75754, "time": 2.73756}
{"mode": "train", "epoch": 1, "iter": 600, "lr": 0.0, "memory": 31487, "data_time": 0.01897, "decode.loss_cls": 1.49253, "decode.loss_mask": 0.96093, "decode.loss_dice": 1.558, "decode.d0.loss_cls": 6.01615, "decode.d0.loss_mask": 1.0982, "decode.d0.loss_dice": 1.94673, "decode.d1.loss_cls": 2.181, "decode.d1.loss_mask": 0.97275, "decode.d1.loss_dice": 1.6872, "decode.d2.loss_cls": 1.72072, "decode.d2.loss_mask": 0.96568, "decode.d2.loss_dice": 1.59503, "decode.d3.loss_cls": 1.5668, "decode.d3.loss_mask": 0.93843, "decode.d3.loss_dice": 1.57275, "decode.d4.loss_cls": 1.53257, "decode.d4.loss_mask": 0.9567, "decode.d4.loss_dice": 1.54229, "decode.d5.loss_cls": 1.52831, "decode.d5.loss_mask": 0.95903, "decode.d5.loss_dice": 1.5542, "decode.d6.loss_cls": 1.53621, "decode.d6.loss_mask": 0.95044, "decode.d6.loss_dice": 1.53241, "decode.d7.loss_cls": 1.51278, "decode.d7.loss_mask": 0.95426, "decode.d7.loss_dice": 1.532, "decode.d8.loss_cls": 1.49443, "decode.d8.loss_mask": 0.95208, "decode.d8.loss_dice": 1.55413, "loss": 46.36472, "time": 2.73346}
{"mode": "train", "epoch": 1, "iter": 650, "lr": 0.0, "memory": 31487, "data_time": 0.01965, "decode.loss_cls": 1.36065, "decode.loss_mask": 0.95063, "decode.loss_dice": 1.58485, "decode.d0.loss_cls": 6.04952, "decode.d0.loss_mask": 1.07823, "decode.d0.loss_dice": 1.9258, "decode.d1.loss_cls": 1.95215, "decode.d1.loss_mask": 1.00944, "decode.d1.loss_dice": 1.72759, "decode.d2.loss_cls": 1.54587, "decode.d2.loss_mask": 0.98999, "decode.d2.loss_dice": 1.64077, "decode.d3.loss_cls": 1.42401, "decode.d3.loss_mask": 0.9856, "decode.d3.loss_dice": 1.6286, "decode.d4.loss_cls": 1.39007, "decode.d4.loss_mask": 0.97631, "decode.d4.loss_dice": 1.62076, "decode.d5.loss_cls": 1.39455, "decode.d5.loss_mask": 0.98218, "decode.d5.loss_dice": 1.59955, "decode.d6.loss_cls": 1.3942, "decode.d6.loss_mask": 0.97069, "decode.d6.loss_dice": 1.60067, "decode.d7.loss_cls": 1.35748, "decode.d7.loss_mask": 0.96702, "decode.d7.loss_dice": 1.61046, "decode.d8.loss_cls": 1.33383, "decode.d8.loss_mask": 0.95367, "decode.d8.loss_dice": 1.60017, "loss": 45.60529, "time": 2.73492}
{"mode": "train", "epoch": 1, "iter": 700, "lr": 0.0, "memory": 31487, "data_time": 0.01929, "decode.loss_cls": 1.23811, "decode.loss_mask": 0.95816, "decode.loss_dice": 1.61153, "decode.d0.loss_cls": 6.04334, "decode.d0.loss_mask": 1.06574, "decode.d0.loss_dice": 1.92622, "decode.d1.loss_cls": 1.82973, "decode.d1.loss_mask": 0.97154, "decode.d1.loss_dice": 1.68995, "decode.d2.loss_cls": 1.47673, "decode.d2.loss_mask": 0.98673, "decode.d2.loss_dice": 1.64301, "decode.d3.loss_cls": 1.3827, "decode.d3.loss_mask": 0.96838, "decode.d3.loss_dice": 1.58944, "decode.d4.loss_cls": 1.34015, "decode.d4.loss_mask": 0.97422, "decode.d4.loss_dice": 1.61292, "decode.d5.loss_cls": 1.30345, "decode.d5.loss_mask": 0.97276, "decode.d5.loss_dice": 1.60629, "decode.d6.loss_cls": 1.26202, "decode.d6.loss_mask": 0.98283, "decode.d6.loss_dice": 1.60245, "decode.d7.loss_cls": 1.2341, "decode.d7.loss_mask": 0.97876, "decode.d7.loss_dice": 1.61168, "decode.d8.loss_cls": 1.22109, "decode.d8.loss_mask": 0.9665, "decode.d8.loss_dice": 1.63612, "loss": 44.68664, "time": 2.7358}
{"mode": "train", "epoch": 2, "iter": 750, "lr": 0.0, "memory": 31487, "data_time": 0.06847, "decode.loss_cls": 1.14361, "decode.loss_mask": 0.94253, "decode.loss_dice": 1.62216, "decode.d0.loss_cls": 5.99293, "decode.d0.loss_mask": 1.02444, "decode.d0.loss_dice": 1.92899, "decode.d1.loss_cls": 1.57907, "decode.d1.loss_mask": 0.93662, "decode.d1.loss_dice": 1.72572, "decode.d2.loss_cls": 1.28918, "decode.d2.loss_mask": 0.92949, "decode.d2.loss_dice": 1.67016, "decode.d3.loss_cls": 1.25242, "decode.d3.loss_mask": 0.90405, "decode.d3.loss_dice": 1.6261, "decode.d4.loss_cls": 1.19201, "decode.d4.loss_mask": 0.9272, "decode.d4.loss_dice": 1.62841, "decode.d5.loss_cls": 1.16832, "decode.d5.loss_mask": 0.91714, "decode.d5.loss_dice": 1.62535, "decode.d6.loss_cls": 1.16591, "decode.d6.loss_mask": 0.92061, "decode.d6.loss_dice": 1.60924, "decode.d7.loss_cls": 1.12872, "decode.d7.loss_mask": 0.92959, "decode.d7.loss_dice": 1.61524, "decode.d8.loss_cls": 1.12541, "decode.d8.loss_mask": 0.93402, "decode.d8.loss_dice": 1.6329, "loss": 43.08752, "time": 2.78906}
{"mode": "train", "epoch": 2, "iter": 800, "lr": 0.0, "memory": 31487, "data_time": 0.02065, "decode.loss_cls": 1.09162, "decode.loss_mask": 0.93187, "decode.loss_dice": 1.58536, "decode.d0.loss_cls": 6.00393, "decode.d0.loss_mask": 1.05496, "decode.d0.loss_dice": 1.92245, "decode.d1.loss_cls": 1.44789, "decode.d1.loss_mask": 0.99346, "decode.d1.loss_dice": 1.71524, "decode.d2.loss_cls": 1.21531, "decode.d2.loss_mask": 0.95576, "decode.d2.loss_dice": 1.62736, "decode.d3.loss_cls": 1.14658, "decode.d3.loss_mask": 0.94712, "decode.d3.loss_dice": 1.61044, "decode.d4.loss_cls": 1.09476, "decode.d4.loss_mask": 0.947, "decode.d4.loss_dice": 1.59385, "decode.d5.loss_cls": 1.12042, "decode.d5.loss_mask": 0.93646, "decode.d5.loss_dice": 1.584, "decode.d6.loss_cls": 1.1121, "decode.d6.loss_mask": 0.93706, "decode.d6.loss_dice": 1.55916, "decode.d7.loss_cls": 1.09126, "decode.d7.loss_mask": 0.93393, "decode.d7.loss_dice": 1.59594, "decode.d8.loss_cls": 1.08627, "decode.d8.loss_mask": 0.92959, "decode.d8.loss_dice": 1.57504, "loss": 42.34619, "time": 2.74456}
{"mode": "train", "epoch": 2, "iter": 850, "lr": 0.0, "memory": 31487, "data_time": 0.02233, "decode.loss_cls": 0.95118, "decode.loss_mask": 0.93267, "decode.loss_dice": 1.55587, "decode.d0.loss_cls": 5.9951, "decode.d0.loss_mask": 1.00087, "decode.d0.loss_dice": 1.8365, "decode.d1.loss_cls": 1.30885, "decode.d1.loss_mask": 0.9682, "decode.d1.loss_dice": 1.65317, "decode.d2.loss_cls": 1.08128, "decode.d2.loss_mask": 0.95051, "decode.d2.loss_dice": 1.57085, "decode.d3.loss_cls": 1.03609, "decode.d3.loss_mask": 0.91364, "decode.d3.loss_dice": 1.54619, "decode.d4.loss_cls": 0.99318, "decode.d4.loss_mask": 0.93478, "decode.d4.loss_dice": 1.55613, "decode.d5.loss_cls": 0.96688, "decode.d5.loss_mask": 0.93385, "decode.d5.loss_dice": 1.55939, "decode.d6.loss_cls": 0.97171, "decode.d6.loss_mask": 0.93687, "decode.d6.loss_dice": 1.53958, "decode.d7.loss_cls": 0.97147, "decode.d7.loss_mask": 0.93428, "decode.d7.loss_dice": 1.56102, "decode.d8.loss_cls": 0.93559, "decode.d8.loss_mask": 0.93489, "decode.d8.loss_dice": 1.56858, "loss": 40.59917, "time": 2.74497}
{"mode": "train", "epoch": 2, "iter": 900, "lr": 0.0, "memory": 31487, "data_time": 0.02363, "decode.loss_cls": 1.05393, "decode.loss_mask": 0.95064, "decode.loss_dice": 1.58738, "decode.d0.loss_cls": 6.01072, "decode.d0.loss_mask": 1.04799, "decode.d0.loss_dice": 1.87135, "decode.d1.loss_cls": 1.26956, "decode.d1.loss_mask": 0.97446, "decode.d1.loss_dice": 1.71476, "decode.d2.loss_cls": 1.13297, "decode.d2.loss_mask": 0.94047, "decode.d2.loss_dice": 1.6545, "decode.d3.loss_cls": 1.08409, "decode.d3.loss_mask": 0.93562, "decode.d3.loss_dice": 1.60948, "decode.d4.loss_cls": 1.0462, "decode.d4.loss_mask": 0.95095, "decode.d4.loss_dice": 1.60798, "decode.d5.loss_cls": 1.05617, "decode.d5.loss_mask": 0.95614, "decode.d5.loss_dice": 1.61991, "decode.d6.loss_cls": 1.08772, "decode.d6.loss_mask": 0.95372, "decode.d6.loss_dice": 1.59579, "decode.d7.loss_cls": 1.04095, "decode.d7.loss_mask": 0.95516, "decode.d7.loss_dice": 1.61743, "decode.d8.loss_cls": 1.04593, "decode.d8.loss_mask": 0.96014, "decode.d8.loss_dice": 1.59931, "loss": 41.93143, "time": 2.83918}
{"mode": "train", "epoch": 2, "iter": 950, "lr": 0.0, "memory": 31487, "data_time": 0.02354, "decode.loss_cls": 0.9372, "decode.loss_mask": 0.91242, "decode.loss_dice": 1.57347, "decode.d0.loss_cls": 5.98449, "decode.d0.loss_mask": 0.99446, "decode.d0.loss_dice": 1.85409, "decode.d1.loss_cls": 1.10456, "decode.d1.loss_mask": 0.94876, "decode.d1.loss_dice": 1.6915, "decode.d2.loss_cls": 0.99351, "decode.d2.loss_mask": 0.91861, "decode.d2.loss_dice": 1.59117, "decode.d3.loss_cls": 0.97657, "decode.d3.loss_mask": 0.92723, "decode.d3.loss_dice": 1.58631, "decode.d4.loss_cls": 0.92834, "decode.d4.loss_mask": 0.92925, "decode.d4.loss_dice": 1.58438, "decode.d5.loss_cls": 0.91897, "decode.d5.loss_mask": 0.92387, "decode.d5.loss_dice": 1.5719, "decode.d6.loss_cls": 0.91878, "decode.d6.loss_mask": 0.91584, "decode.d6.loss_dice": 1.57177, "decode.d7.loss_cls": 0.89956, "decode.d7.loss_mask": 0.9089, "decode.d7.loss_dice": 1.56412, "decode.d8.loss_cls": 0.88475, "decode.d8.loss_mask": 0.91535, "decode.d8.loss_dice": 1.58384, "loss": 40.01398, "time": 3.07861}
{"mode": "train", "epoch": 2, "iter": 1000, "lr": 0.0, "memory": 31487, "data_time": 0.02235, "decode.loss_cls": 0.94153, "decode.loss_mask": 0.91398, "decode.loss_dice": 1.59209, "decode.d0.loss_cls": 5.95661, "decode.d0.loss_mask": 1.01445, "decode.d0.loss_dice": 1.83545, "decode.d1.loss_cls": 1.03981, "decode.d1.loss_mask": 0.94054, "decode.d1.loss_dice": 1.71509, "decode.d2.loss_cls": 0.95292, "decode.d2.loss_mask": 0.94135, "decode.d2.loss_dice": 1.63584, "decode.d3.loss_cls": 0.97345, "decode.d3.loss_mask": 0.90575, "decode.d3.loss_dice": 1.59431, "decode.d4.loss_cls": 0.93021, "decode.d4.loss_mask": 0.90024, "decode.d4.loss_dice": 1.58803, "decode.d5.loss_cls": 0.95188, "decode.d5.loss_mask": 0.91088, "decode.d5.loss_dice": 1.59938, "decode.d6.loss_cls": 0.93366, "decode.d6.loss_mask": 0.90955, "decode.d6.loss_dice": 1.58396, "decode.d7.loss_cls": 0.90198, "decode.d7.loss_mask": 0.9133, "decode.d7.loss_dice": 1.58808, "decode.d8.loss_cls": 0.90191, "decode.d8.loss_mask": 0.91835, "decode.d8.loss_dice": 1.59675, "loss": 40.08132, "time": 3.22866}
