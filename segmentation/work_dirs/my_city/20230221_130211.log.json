{"env_info": "sys.platform: linux\nPython: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\nCUDA available: True\nGPU 0: NVIDIA A100-PCIE-40GB\nCUDA_HOME: /usr/local/cuda\nNVCC: Build cuda_11.1.TC455_06.29190527_0\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.9.0+cu111\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.10.0+cu111\nOpenCV: 4.6.0\nMMCV: 1.4.2\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.1\nMMSegmentation: 0.20.2+a1b84a3", "seed": 1510193464, "exp_name": "my_city.py", "mmseg_version": "0.20.2+a1b84a3", "config": "num_things_classes = 0\nnum_stuff_classes = 16\nnum_classes = 16\nnorm_cfg = dict(type='SyncBN', requires_grad=True)\nmodel = dict(\n    type='EncoderDecoderMask2FormerAug',\n    pretrained='pretrained/beit_large_patch16_224_pt22k_ft22k.pth',\n    backbone=dict(\n        type='BEiTAdapter',\n        patch_size=16,\n        embed_dim=1024,\n        depth=24,\n        num_heads=16,\n        mlp_ratio=4,\n        qkv_bias=True,\n        use_abs_pos_emb=False,\n        use_rel_pos_bias=True,\n        img_size=896,\n        init_values=1e-06,\n        drop_path_rate=0.3,\n        conv_inplane=64,\n        n_points=4,\n        deform_num_heads=16,\n        cffn_ratio=0.25,\n        deform_ratio=0.5,\n        with_cp=True,\n        interaction_indexes=[[0, 5], [6, 11], [12, 17], [18, 23]],\n        pretrained='pretrained/beit_large_patch16_224_pt22k_ft22k.pth'),\n    decode_head=dict(\n        type='Mask2FormerHead',\n        in_channels=[1024, 1024, 1024, 1024],\n        feat_channels=1024,\n        out_channels=1024,\n        in_index=[0, 1, 2, 3],\n        num_things_classes=0,\n        num_stuff_classes=16,\n        num_queries=100,\n        num_transformer_feat_level=3,\n        pixel_decoder=dict(\n            type='MSDeformAttnPixelDecoder',\n            num_outs=3,\n            norm_cfg=dict(type='GN', num_groups=32),\n            act_cfg=dict(type='ReLU'),\n            encoder=dict(\n                type='DetrTransformerEncoder',\n                num_layers=6,\n                transformerlayers=dict(\n                    type='BaseTransformerLayer',\n                    attn_cfgs=dict(\n                        type='MultiScaleDeformableAttention',\n                        embed_dims=1024,\n                        num_heads=32,\n                        num_levels=3,\n                        num_points=4,\n                        im2col_step=64,\n                        dropout=0.0,\n                        batch_first=False,\n                        norm_cfg=None,\n                        init_cfg=None),\n                    ffn_cfgs=dict(\n                        type='FFN',\n                        embed_dims=1024,\n                        feedforward_channels=4096,\n                        num_fcs=2,\n                        ffn_drop=0.0,\n                        act_cfg=dict(type='ReLU', inplace=True),\n                        with_cp=True),\n                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),\n                init_cfg=None),\n            positional_encoding=dict(\n                type='SinePositionalEncoding', num_feats=512, normalize=True),\n            init_cfg=None),\n        enforce_decoder_input_project=False,\n        positional_encoding=dict(\n            type='SinePositionalEncoding', num_feats=512, normalize=True),\n        transformer_decoder=dict(\n            type='DetrTransformerDecoder',\n            return_intermediate=True,\n            num_layers=9,\n            transformerlayers=dict(\n                type='DetrTransformerDecoderLayer',\n                attn_cfgs=dict(\n                    type='MultiheadAttention',\n                    embed_dims=1024,\n                    num_heads=32,\n                    attn_drop=0.0,\n                    proj_drop=0.0,\n                    dropout_layer=None,\n                    batch_first=False),\n                ffn_cfgs=dict(\n                    embed_dims=1024,\n                    feedforward_channels=4096,\n                    num_fcs=2,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    ffn_drop=0.0,\n                    dropout_layer=None,\n                    add_identity=True,\n                    with_cp=True),\n                feedforward_channels=4096,\n                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',\n                                 'ffn', 'norm')),\n            init_cfg=None),\n        loss_cls=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=False,\n            loss_weight=2.0,\n            reduction='mean',\n            class_weight=[\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 0.1\n            ]),\n        loss_mask=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=True,\n            reduction='mean',\n            loss_weight=5.0),\n        loss_dice=dict(\n            type='DiceLoss',\n            use_sigmoid=True,\n            activate=True,\n            reduction='mean',\n            naive_dice=True,\n            eps=1.0,\n            loss_weight=5.0),\n        train_cfg=dict(\n            num_points=12544,\n            oversample_ratio=3.0,\n            importance_sample_ratio=0.75,\n            assigner=dict(\n                type='MaskHungarianAssigner',\n                cls_cost=dict(type='ClassificationCost', weight=2.0),\n                mask_cost=dict(\n                    type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n                dice_cost=dict(\n                    type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n            sampler=dict(type='MaskPseudoSampler')),\n        test_cfg=dict(\n            panoptic_on=True,\n            semantic_on=False,\n            instance_on=True,\n            max_per_image=100,\n            iou_thr=0.8,\n            filter_low_score=True,\n            mode='slide',\n            crop_size=(896, 896),\n            stride=(512, 512))),\n    train_cfg=dict(\n        num_points=12544,\n        oversample_ratio=3.0,\n        importance_sample_ratio=0.75,\n        assigner=dict(\n            type='MaskHungarianAssigner',\n            cls_cost=dict(type='ClassificationCost', weight=2.0),\n            mask_cost=dict(\n                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n            dice_cost=dict(\n                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n        sampler=dict(type='MaskPseudoSampler')),\n    test_cfg=dict(\n        panoptic_on=True,\n        semantic_on=False,\n        instance_on=True,\n        max_per_image=100,\n        iou_thr=0.8,\n        filter_low_score=True,\n        mode='slide',\n        crop_size=(896, 896),\n        stride=(512, 512)),\n    init_cfg=None)\ndataset_type = 'MyDataset'\ndata_root = '/root/autodl-tmp/data'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ncrop_size = (896, 896)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations'),\n    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n    dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),\n    dict(type='RandomFlip', prob=0.5),\n    dict(type='PhotoMetricDistortion'),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),\n    dict(type='ToMask'),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(2048, 1024),\n        img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n        flip=True,\n        transforms=[\n            dict(\n                type='SETR_Resize',\n                keep_ratio=True,\n                crop_size=(896, 896),\n                setr_multi_scale=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=1,\n    train=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/train',\n        ann_dir='annotations/train',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations'),\n            dict(\n                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n            dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),\n            dict(type='RandomFlip', prob=0.5),\n            dict(type='PhotoMetricDistortion'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),\n            dict(type='ToMask'),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n        ]),\n    val=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/val',\n        ann_dir='annotations/val',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2048, 1024),\n                img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n                flip=True,\n                transforms=[\n                    dict(\n                        type='SETR_Resize',\n                        keep_ratio=True,\n                        crop_size=(896, 896),\n                        setr_multi_scale=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/val',\n        ann_dir='annotations/val',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2048, 1024),\n                img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n                flip=True,\n                transforms=[\n                    dict(\n                        type='SETR_Resize',\n                        keep_ratio=True,\n                        crop_size=(896, 896),\n                        setr_multi_scale=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nlog_config = dict(\n    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'pretrained/mask2former_beit_adapter_large_896_80k_cityscapes.pth.tar'\nresume_from = None\nworkflow = [('train', 1)]\ncudnn_benchmark = True\noptimizer = dict(\n    type='AdamW',\n    lr=2e-05,\n    betas=(0.9, 0.999),\n    weight_decay=0.05,\n    constructor='LayerDecayOptimizerConstructor',\n    paramwise_cfg=dict(num_layers=24, layer_decay_rate=0.9))\noptimizer_config = dict()\nlr_config = dict(\n    policy='poly',\n    warmup='linear',\n    warmup_iters=1500,\n    warmup_ratio=1e-06,\n    power=1.0,\n    min_lr=0.0,\n    by_epoch=False)\nrunner = dict(type='IterBasedRunner', max_iters=80000)\ncheckpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)\nevaluation = dict(\n    interval=1000, metric='mIoU', pre_eval=True, save_best='mIoU')\npretrained = 'pretrained/beit_large_patch16_224_pt22k_ft22k.pth'\nwork_dir = './work_dirs/my_city'\ngpu_ids = range(0, 1)\nauto_resume = False\nseed = 1510193464\n", "CLASSES": ["WATER", "ASPHALT", "GRASS", "HUMAN", "ANIMAL", "HIGH_VEGETATION", "GROUND_VEHICLE", "FACADE", "WIRE", "GARDEN_FURNITURE", "CONCRETE", "ROOF", "GRAVEL", "SOIL", "PRIMEAIR_PATTERN", "SNOW"], "PALETTE": [[148, 218, 255], [85, 85, 85], [200, 219, 190], [166, 133, 226], [255, 171, 225], [40, 150, 114], [234, 144, 133], [89, 82, 96], [255, 255, 0], [110, 87, 121], [205, 201, 195], [212, 80, 121], [159, 135, 114], [102, 90, 72], [255, 255, 102], [251, 247, 240]], "hook_msgs": {}}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 31506, "data_time": 0.02958, "decode.loss_cls": 6.10985, "decode.loss_mask": 2.13281, "decode.loss_dice": 2.6914, "decode.d0.loss_cls": 5.82812, "decode.d0.loss_mask": 2.1682, "decode.d0.loss_dice": 3.13718, "decode.d1.loss_cls": 6.19659, "decode.d1.loss_mask": 2.13392, "decode.d1.loss_dice": 2.82542, "decode.d2.loss_cls": 5.97422, "decode.d2.loss_mask": 2.08874, "decode.d2.loss_dice": 2.77782, "decode.d3.loss_cls": 6.04684, "decode.d3.loss_mask": 2.01706, "decode.d3.loss_dice": 2.69928, "decode.d4.loss_cls": 6.12996, "decode.d4.loss_mask": 2.09351, "decode.d4.loss_dice": 2.71468, "decode.d5.loss_cls": 6.1548, "decode.d5.loss_mask": 2.0004, "decode.d5.loss_dice": 2.70827, "decode.d6.loss_cls": 6.30566, "decode.d6.loss_mask": 2.05444, "decode.d6.loss_dice": 2.70148, "decode.d7.loss_cls": 6.02111, "decode.d7.loss_mask": 2.08956, "decode.d7.loss_dice": 2.73252, "decode.d8.loss_cls": 5.88618, "decode.d8.loss_mask": 2.085, "decode.d8.loss_dice": 2.7118, "loss": 109.21683, "time": 2.82595}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.0, "memory": 31506, "data_time": 0.02253, "decode.loss_cls": 4.85456, "decode.loss_mask": 1.92439, "decode.loss_dice": 2.57362, "decode.d0.loss_cls": 5.8736, "decode.d0.loss_mask": 2.13587, "decode.d0.loss_dice": 3.04925, "decode.d1.loss_cls": 5.67991, "decode.d1.loss_mask": 2.03687, "decode.d1.loss_dice": 2.73233, "decode.d2.loss_cls": 5.1712, "decode.d2.loss_mask": 1.9724, "decode.d2.loss_dice": 2.66606, "decode.d3.loss_cls": 4.99593, "decode.d3.loss_mask": 1.85792, "decode.d3.loss_dice": 2.5653, "decode.d4.loss_cls": 4.95513, "decode.d4.loss_mask": 1.89482, "decode.d4.loss_dice": 2.56192, "decode.d5.loss_cls": 4.97354, "decode.d5.loss_mask": 1.82805, "decode.d5.loss_dice": 2.56932, "decode.d6.loss_cls": 5.06701, "decode.d6.loss_mask": 1.83372, "decode.d6.loss_dice": 2.58322, "decode.d7.loss_cls": 4.86196, "decode.d7.loss_mask": 1.83368, "decode.d7.loss_dice": 2.57728, "decode.d8.loss_cls": 4.70689, "decode.d8.loss_mask": 1.86401, "decode.d8.loss_dice": 2.56214, "loss": 96.7619, "time": 2.73339}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.0, "memory": 31506, "data_time": 0.02403, "decode.loss_cls": 3.90479, "decode.loss_mask": 1.50031, "decode.loss_dice": 2.4103, "decode.d0.loss_cls": 5.89148, "decode.d0.loss_mask": 1.87439, "decode.d0.loss_dice": 2.8824, "decode.d1.loss_cls": 4.8671, "decode.d1.loss_mask": 1.71725, "decode.d1.loss_dice": 2.61977, "decode.d2.loss_cls": 4.1555, "decode.d2.loss_mask": 1.58379, "decode.d2.loss_dice": 2.51131, "decode.d3.loss_cls": 3.96534, "decode.d3.loss_mask": 1.52382, "decode.d3.loss_dice": 2.47008, "decode.d4.loss_cls": 3.96845, "decode.d4.loss_mask": 1.53129, "decode.d4.loss_dice": 2.45615, "decode.d5.loss_cls": 3.9385, "decode.d5.loss_mask": 1.50201, "decode.d5.loss_dice": 2.42023, "decode.d6.loss_cls": 3.97665, "decode.d6.loss_mask": 1.47357, "decode.d6.loss_dice": 2.43065, "decode.d7.loss_cls": 3.91547, "decode.d7.loss_mask": 1.46295, "decode.d7.loss_dice": 2.42482, "decode.d8.loss_cls": 3.85516, "decode.d8.loss_mask": 1.47505, "decode.d8.loss_dice": 2.42539, "loss": 83.13398, "time": 2.75456}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.0, "memory": 31506, "data_time": 0.023, "decode.loss_cls": 3.51785, "decode.loss_mask": 1.33421, "decode.loss_dice": 2.10698, "decode.d0.loss_cls": 5.96378, "decode.d0.loss_mask": 1.82966, "decode.d0.loss_dice": 2.60168, "decode.d1.loss_cls": 4.07877, "decode.d1.loss_mask": 1.56317, "decode.d1.loss_dice": 2.34402, "decode.d2.loss_cls": 3.62693, "decode.d2.loss_mask": 1.41925, "decode.d2.loss_dice": 2.25371, "decode.d3.loss_cls": 3.56118, "decode.d3.loss_mask": 1.36839, "decode.d3.loss_dice": 2.1832, "decode.d4.loss_cls": 3.5662, "decode.d4.loss_mask": 1.37837, "decode.d4.loss_dice": 2.16052, "decode.d5.loss_cls": 3.57025, "decode.d5.loss_mask": 1.35115, "decode.d5.loss_dice": 2.13624, "decode.d6.loss_cls": 3.56728, "decode.d6.loss_mask": 1.33033, "decode.d6.loss_dice": 2.13425, "decode.d7.loss_cls": 3.51613, "decode.d7.loss_mask": 1.32797, "decode.d7.loss_dice": 2.1031, "decode.d8.loss_cls": 3.51024, "decode.d8.loss_mask": 1.33726, "decode.d8.loss_dice": 2.12277, "loss": 74.86483, "time": 2.73363}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.0, "memory": 31506, "data_time": 0.02343, "decode.loss_cls": 3.3253, "decode.loss_mask": 1.2431, "decode.loss_dice": 2.06322, "decode.d0.loss_cls": 5.98729, "decode.d0.loss_mask": 1.7103, "decode.d0.loss_dice": 2.57749, "decode.d1.loss_cls": 3.78579, "decode.d1.loss_mask": 1.40713, "decode.d1.loss_dice": 2.32448, "decode.d2.loss_cls": 3.53039, "decode.d2.loss_mask": 1.29202, "decode.d2.loss_dice": 2.20908, "decode.d3.loss_cls": 3.44076, "decode.d3.loss_mask": 1.24654, "decode.d3.loss_dice": 2.12803, "decode.d4.loss_cls": 3.42268, "decode.d4.loss_mask": 1.24608, "decode.d4.loss_dice": 2.13191, "decode.d5.loss_cls": 3.40589, "decode.d5.loss_mask": 1.23239, "decode.d5.loss_dice": 2.10521, "decode.d6.loss_cls": 3.37612, "decode.d6.loss_mask": 1.24049, "decode.d6.loss_dice": 2.06886, "decode.d7.loss_cls": 3.29827, "decode.d7.loss_mask": 1.25279, "decode.d7.loss_dice": 2.06702, "decode.d8.loss_cls": 3.32062, "decode.d8.loss_mask": 1.24303, "decode.d8.loss_dice": 2.05246, "loss": 71.73475, "time": 2.74095}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.0, "memory": 31506, "data_time": 0.0237, "decode.loss_cls": 2.91887, "decode.loss_mask": 1.22675, "decode.loss_dice": 1.9342, "decode.d0.loss_cls": 5.98351, "decode.d0.loss_mask": 1.70817, "decode.d0.loss_dice": 2.43462, "decode.d1.loss_cls": 3.53991, "decode.d1.loss_mask": 1.36053, "decode.d1.loss_dice": 2.17898, "decode.d2.loss_cls": 3.26117, "decode.d2.loss_mask": 1.24749, "decode.d2.loss_dice": 2.0782, "decode.d3.loss_cls": 3.1049, "decode.d3.loss_mask": 1.19985, "decode.d3.loss_dice": 2.00076, "decode.d4.loss_cls": 3.03741, "decode.d4.loss_mask": 1.21306, "decode.d4.loss_dice": 1.99683, "decode.d5.loss_cls": 3.00944, "decode.d5.loss_mask": 1.21804, "decode.d5.loss_dice": 1.97131, "decode.d6.loss_cls": 2.96893, "decode.d6.loss_mask": 1.21593, "decode.d6.loss_dice": 1.93814, "decode.d7.loss_cls": 2.88344, "decode.d7.loss_mask": 1.24948, "decode.d7.loss_dice": 1.93758, "decode.d8.loss_cls": 2.91482, "decode.d8.loss_mask": 1.24135, "decode.d8.loss_dice": 1.94056, "loss": 66.91424, "time": 2.74299}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.0, "memory": 31506, "data_time": 0.02179, "decode.loss_cls": 2.44151, "decode.loss_mask": 1.09516, "decode.loss_dice": 1.70858, "decode.d0.loss_cls": 6.03653, "decode.d0.loss_mask": 1.46389, "decode.d0.loss_dice": 2.18251, "decode.d1.loss_cls": 3.22154, "decode.d1.loss_mask": 1.19037, "decode.d1.loss_dice": 1.96753, "decode.d2.loss_cls": 2.85422, "decode.d2.loss_mask": 1.12038, "decode.d2.loss_dice": 1.83121, "decode.d3.loss_cls": 2.64728, "decode.d3.loss_mask": 1.08739, "decode.d3.loss_dice": 1.75396, "decode.d4.loss_cls": 2.56926, "decode.d4.loss_mask": 1.08272, "decode.d4.loss_dice": 1.74094, "decode.d5.loss_cls": 2.53841, "decode.d5.loss_mask": 1.09663, "decode.d5.loss_dice": 1.74121, "decode.d6.loss_cls": 2.46662, "decode.d6.loss_mask": 1.10629, "decode.d6.loss_dice": 1.70545, "decode.d7.loss_cls": 2.38219, "decode.d7.loss_mask": 1.11137, "decode.d7.loss_dice": 1.71185, "decode.d8.loss_cls": 2.40356, "decode.d8.loss_mask": 1.11513, "decode.d8.loss_dice": 1.71406, "loss": 59.08775, "time": 2.82942}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.0, "memory": 31506, "data_time": 0.02138, "decode.loss_cls": 2.24726, "decode.loss_mask": 1.08257, "decode.loss_dice": 1.77545, "decode.d0.loss_cls": 6.06296, "decode.d0.loss_mask": 1.42256, "decode.d0.loss_dice": 2.26624, "decode.d1.loss_cls": 3.0969, "decode.d1.loss_mask": 1.16654, "decode.d1.loss_dice": 2.0097, "decode.d2.loss_cls": 2.6981, "decode.d2.loss_mask": 1.11445, "decode.d2.loss_dice": 1.87968, "decode.d3.loss_cls": 2.46886, "decode.d3.loss_mask": 1.08519, "decode.d3.loss_dice": 1.81595, "decode.d4.loss_cls": 2.37262, "decode.d4.loss_mask": 1.10049, "decode.d4.loss_dice": 1.81563, "decode.d5.loss_cls": 2.31537, "decode.d5.loss_mask": 1.09834, "decode.d5.loss_dice": 1.80365, "decode.d6.loss_cls": 2.26289, "decode.d6.loss_mask": 1.08493, "decode.d6.loss_dice": 1.78402, "decode.d7.loss_cls": 2.20987, "decode.d7.loss_mask": 1.08357, "decode.d7.loss_dice": 1.77219, "decode.d8.loss_cls": 2.22024, "decode.d8.loss_mask": 1.08982, "decode.d8.loss_dice": 1.76824, "loss": 57.97426, "time": 2.81584}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.0, "memory": 31506, "data_time": 0.02027, "decode.loss_cls": 1.94086, "decode.loss_mask": 1.08644, "decode.loss_dice": 1.68186, "decode.d0.loss_cls": 6.04427, "decode.d0.loss_mask": 1.35267, "decode.d0.loss_dice": 2.18543, "decode.d1.loss_cls": 2.75459, "decode.d1.loss_mask": 1.1254, "decode.d1.loss_dice": 1.94838, "decode.d2.loss_cls": 2.35166, "decode.d2.loss_mask": 1.06962, "decode.d2.loss_dice": 1.82936, "decode.d3.loss_cls": 2.14925, "decode.d3.loss_mask": 1.04577, "decode.d3.loss_dice": 1.73603, "decode.d4.loss_cls": 2.02933, "decode.d4.loss_mask": 1.05863, "decode.d4.loss_dice": 1.72299, "decode.d5.loss_cls": 1.98303, "decode.d5.loss_mask": 1.06182, "decode.d5.loss_dice": 1.70963, "decode.d6.loss_cls": 1.93004, "decode.d6.loss_mask": 1.07707, "decode.d6.loss_dice": 1.69611, "decode.d7.loss_cls": 1.86562, "decode.d7.loss_mask": 1.08479, "decode.d7.loss_dice": 1.70118, "decode.d8.loss_cls": 1.91543, "decode.d8.loss_mask": 1.09141, "decode.d8.loss_dice": 1.69455, "loss": 53.92322, "time": 2.72425}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.0, "memory": 31506, "data_time": 0.02104, "decode.loss_cls": 1.70659, "decode.loss_mask": 1.05103, "decode.loss_dice": 1.6629, "decode.d0.loss_cls": 6.04021, "decode.d0.loss_mask": 1.32572, "decode.d0.loss_dice": 2.09347, "decode.d1.loss_cls": 2.50427, "decode.d1.loss_mask": 1.09035, "decode.d1.loss_dice": 1.85288, "decode.d2.loss_cls": 2.07498, "decode.d2.loss_mask": 1.06552, "decode.d2.loss_dice": 1.7419, "decode.d3.loss_cls": 1.87239, "decode.d3.loss_mask": 1.0484, "decode.d3.loss_dice": 1.69109, "decode.d4.loss_cls": 1.79814, "decode.d4.loss_mask": 1.07017, "decode.d4.loss_dice": 1.71556, "decode.d5.loss_cls": 1.75165, "decode.d5.loss_mask": 1.06258, "decode.d5.loss_dice": 1.70301, "decode.d6.loss_cls": 1.71879, "decode.d6.loss_mask": 1.05102, "decode.d6.loss_dice": 1.6932, "decode.d7.loss_cls": 1.6776, "decode.d7.loss_mask": 1.06908, "decode.d7.loss_dice": 1.71037, "decode.d8.loss_cls": 1.6744, "decode.d8.loss_mask": 1.06524, "decode.d8.loss_dice": 1.67985, "loss": 51.26237, "time": 2.86994}
{"mode": "train", "epoch": 1, "iter": 550, "lr": 0.0, "memory": 31506, "data_time": 0.05196, "decode.loss_cls": 1.5953, "decode.loss_mask": 0.97753, "decode.loss_dice": 1.69087, "decode.d0.loss_cls": 5.99973, "decode.d0.loss_mask": 1.15209, "decode.d0.loss_dice": 2.05929, "decode.d1.loss_cls": 2.30718, "decode.d1.loss_mask": 0.99275, "decode.d1.loss_dice": 1.85435, "decode.d2.loss_cls": 1.88063, "decode.d2.loss_mask": 0.99549, "decode.d2.loss_dice": 1.74838, "decode.d3.loss_cls": 1.721, "decode.d3.loss_mask": 0.97172, "decode.d3.loss_dice": 1.70756, "decode.d4.loss_cls": 1.63861, "decode.d4.loss_mask": 0.9826, "decode.d4.loss_dice": 1.72767, "decode.d5.loss_cls": 1.64333, "decode.d5.loss_mask": 0.97826, "decode.d5.loss_dice": 1.70921, "decode.d6.loss_cls": 1.56792, "decode.d6.loss_mask": 0.97918, "decode.d6.loss_dice": 1.70636, "decode.d7.loss_cls": 1.53554, "decode.d7.loss_mask": 0.98287, "decode.d7.loss_dice": 1.70305, "decode.d8.loss_cls": 1.54753, "decode.d8.loss_mask": 0.97285, "decode.d8.loss_dice": 1.68331, "loss": 49.01216, "time": 2.85149}
{"mode": "train", "epoch": 1, "iter": 600, "lr": 0.0, "memory": 31506, "data_time": 0.02172, "decode.loss_cls": 1.42891, "decode.loss_mask": 0.97961, "decode.loss_dice": 1.62945, "decode.d0.loss_cls": 6.01749, "decode.d0.loss_mask": 1.17145, "decode.d0.loss_dice": 2.04723, "decode.d1.loss_cls": 2.08335, "decode.d1.loss_mask": 0.99805, "decode.d1.loss_dice": 1.8308, "decode.d2.loss_cls": 1.65316, "decode.d2.loss_mask": 1.00401, "decode.d2.loss_dice": 1.70516, "decode.d3.loss_cls": 1.54211, "decode.d3.loss_mask": 0.98667, "decode.d3.loss_dice": 1.66173, "decode.d4.loss_cls": 1.47364, "decode.d4.loss_mask": 1.00344, "decode.d4.loss_dice": 1.66657, "decode.d5.loss_cls": 1.45822, "decode.d5.loss_mask": 0.99272, "decode.d5.loss_dice": 1.65872, "decode.d6.loss_cls": 1.43521, "decode.d6.loss_mask": 0.98103, "decode.d6.loss_dice": 1.63157, "decode.d7.loss_cls": 1.3838, "decode.d7.loss_mask": 0.99206, "decode.d7.loss_dice": 1.62501, "decode.d8.loss_cls": 1.39034, "decode.d8.loss_mask": 0.97637, "decode.d8.loss_dice": 1.64159, "loss": 47.04948, "time": 2.74747}
{"mode": "train", "epoch": 1, "iter": 650, "lr": 0.0, "memory": 31506, "data_time": 0.02279, "decode.loss_cls": 1.36736, "decode.loss_mask": 0.92483, "decode.loss_dice": 1.68209, "decode.d0.loss_cls": 5.97401, "decode.d0.loss_mask": 1.03595, "decode.d0.loss_dice": 2.05954, "decode.d1.loss_cls": 1.9143, "decode.d1.loss_mask": 0.93572, "decode.d1.loss_dice": 1.82961, "decode.d2.loss_cls": 1.57946, "decode.d2.loss_mask": 0.92846, "decode.d2.loss_dice": 1.74227, "decode.d3.loss_cls": 1.48251, "decode.d3.loss_mask": 0.91645, "decode.d3.loss_dice": 1.72591, "decode.d4.loss_cls": 1.4282, "decode.d4.loss_mask": 0.92466, "decode.d4.loss_dice": 1.71063, "decode.d5.loss_cls": 1.41606, "decode.d5.loss_mask": 0.90493, "decode.d5.loss_dice": 1.69177, "decode.d6.loss_cls": 1.38251, "decode.d6.loss_mask": 0.92148, "decode.d6.loss_dice": 1.69208, "decode.d7.loss_cls": 1.33627, "decode.d7.loss_mask": 0.93009, "decode.d7.loss_dice": 1.67613, "decode.d8.loss_cls": 1.33706, "decode.d8.loss_mask": 0.92108, "decode.d8.loss_dice": 1.68322, "loss": 46.05463, "time": 2.73667}
{"mode": "train", "epoch": 1, "iter": 700, "lr": 0.0, "memory": 31506, "data_time": 0.01884, "decode.loss_cls": 1.22833, "decode.loss_mask": 0.88339, "decode.loss_dice": 1.59089, "decode.d0.loss_cls": 6.01623, "decode.d0.loss_mask": 1.01021, "decode.d0.loss_dice": 1.92569, "decode.d1.loss_cls": 1.65715, "decode.d1.loss_mask": 0.91989, "decode.d1.loss_dice": 1.6924, "decode.d2.loss_cls": 1.37009, "decode.d2.loss_mask": 0.88812, "decode.d2.loss_dice": 1.6302, "decode.d3.loss_cls": 1.30627, "decode.d3.loss_mask": 0.86717, "decode.d3.loss_dice": 1.58647, "decode.d4.loss_cls": 1.28401, "decode.d4.loss_mask": 0.8796, "decode.d4.loss_dice": 1.60663, "decode.d5.loss_cls": 1.25637, "decode.d5.loss_mask": 0.88384, "decode.d5.loss_dice": 1.61671, "decode.d6.loss_cls": 1.23844, "decode.d6.loss_mask": 0.89441, "decode.d6.loss_dice": 1.58462, "decode.d7.loss_cls": 1.22046, "decode.d7.loss_mask": 0.89701, "decode.d7.loss_dice": 1.59097, "decode.d8.loss_cls": 1.19868, "decode.d8.loss_mask": 0.88839, "decode.d8.loss_dice": 1.60959, "loss": 43.22224, "time": 2.7198}
{"mode": "train", "epoch": 2, "iter": 750, "lr": 0.0, "memory": 31506, "data_time": 0.06857, "decode.loss_cls": 1.1131, "decode.loss_mask": 0.97453, "decode.loss_dice": 1.58417, "decode.d0.loss_cls": 5.99375, "decode.d0.loss_mask": 1.08276, "decode.d0.loss_dice": 1.89085, "decode.d1.loss_cls": 1.46874, "decode.d1.loss_mask": 1.03555, "decode.d1.loss_dice": 1.6675, "decode.d2.loss_cls": 1.22058, "decode.d2.loss_mask": 0.9954, "decode.d2.loss_dice": 1.57582, "decode.d3.loss_cls": 1.16902, "decode.d3.loss_mask": 0.98868, "decode.d3.loss_dice": 1.56114, "decode.d4.loss_cls": 1.12825, "decode.d4.loss_mask": 0.99304, "decode.d4.loss_dice": 1.5818, "decode.d5.loss_cls": 1.13891, "decode.d5.loss_mask": 0.97857, "decode.d5.loss_dice": 1.58528, "decode.d6.loss_cls": 1.12384, "decode.d6.loss_mask": 0.98291, "decode.d6.loss_dice": 1.58312, "decode.d7.loss_cls": 1.09959, "decode.d7.loss_mask": 0.97992, "decode.d7.loss_dice": 1.57452, "decode.d8.loss_cls": 1.08965, "decode.d8.loss_mask": 0.98454, "decode.d8.loss_dice": 1.57713, "loss": 42.72265, "time": 2.77431}
