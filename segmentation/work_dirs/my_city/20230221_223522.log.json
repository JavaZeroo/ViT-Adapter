{"env_info": "sys.platform: linux\nPython: 3.8.10 (default, Jun  4 2021, 15:09:15) [GCC 7.5.0]\nCUDA available: True\nGPU 0: NVIDIA A100-PCIE-40GB\nCUDA_HOME: /usr/local/cuda\nNVCC: Build cuda_11.1.TC455_06.29190527_0\nGCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\nPyTorch: 1.9.0+cu111\nPyTorch compiling details: PyTorch built with:\n  - GCC 7.3\n  - C++ Version: 201402\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.1\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n  - CuDNN 8.0.5\n  - Magma 2.5.2\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n\nTorchVision: 0.10.0+cu111\nOpenCV: 4.6.0\nMMCV: 1.4.2\nMMCV Compiler: GCC 7.3\nMMCV CUDA Compiler: 11.1\nMMSegmentation: 0.20.2+a1b84a3", "seed": 613560434, "exp_name": "my_city.py", "mmseg_version": "0.20.2+a1b84a3", "config": "num_things_classes = 0\nnum_stuff_classes = 16\nnum_classes = 16\nnorm_cfg = dict(type='SyncBN', requires_grad=True)\nmodel = dict(\n    type='EncoderDecoderMask2FormerAug',\n    pretrained='pretrained/beit_large_patch16_224_pt22k_ft22k.pth',\n    backbone=dict(\n        type='BEiTAdapter',\n        patch_size=16,\n        embed_dim=1024,\n        depth=24,\n        num_heads=16,\n        mlp_ratio=4,\n        qkv_bias=True,\n        use_abs_pos_emb=False,\n        use_rel_pos_bias=True,\n        img_size=896,\n        init_values=1e-06,\n        drop_path_rate=0.3,\n        conv_inplane=64,\n        n_points=4,\n        deform_num_heads=16,\n        cffn_ratio=0.25,\n        deform_ratio=0.5,\n        with_cp=True,\n        interaction_indexes=[[0, 5], [6, 11], [12, 17], [18, 23]],\n        pretrained='pretrained/beit_large_patch16_224_pt22k_ft22k.pth'),\n    decode_head=dict(\n        type='Mask2FormerHead',\n        in_channels=[1024, 1024, 1024, 1024],\n        feat_channels=1024,\n        out_channels=1024,\n        in_index=[0, 1, 2, 3],\n        num_things_classes=0,\n        num_stuff_classes=16,\n        num_queries=100,\n        num_transformer_feat_level=3,\n        pixel_decoder=dict(\n            type='MSDeformAttnPixelDecoder',\n            num_outs=3,\n            norm_cfg=dict(type='GN', num_groups=32),\n            act_cfg=dict(type='ReLU'),\n            encoder=dict(\n                type='DetrTransformerEncoder',\n                num_layers=6,\n                transformerlayers=dict(\n                    type='BaseTransformerLayer',\n                    attn_cfgs=dict(\n                        type='MultiScaleDeformableAttention',\n                        embed_dims=1024,\n                        num_heads=32,\n                        num_levels=3,\n                        num_points=4,\n                        im2col_step=64,\n                        dropout=0.0,\n                        batch_first=False,\n                        norm_cfg=None,\n                        init_cfg=None),\n                    ffn_cfgs=dict(\n                        type='FFN',\n                        embed_dims=1024,\n                        feedforward_channels=4096,\n                        num_fcs=2,\n                        ffn_drop=0.0,\n                        act_cfg=dict(type='ReLU', inplace=True),\n                        with_cp=True),\n                    operation_order=('self_attn', 'norm', 'ffn', 'norm')),\n                init_cfg=None),\n            positional_encoding=dict(\n                type='SinePositionalEncoding', num_feats=512, normalize=True),\n            init_cfg=None),\n        enforce_decoder_input_project=False,\n        positional_encoding=dict(\n            type='SinePositionalEncoding', num_feats=512, normalize=True),\n        transformer_decoder=dict(\n            type='DetrTransformerDecoder',\n            return_intermediate=True,\n            num_layers=9,\n            transformerlayers=dict(\n                type='DetrTransformerDecoderLayer',\n                attn_cfgs=dict(\n                    type='MultiheadAttention',\n                    embed_dims=1024,\n                    num_heads=32,\n                    attn_drop=0.0,\n                    proj_drop=0.0,\n                    dropout_layer=None,\n                    batch_first=False),\n                ffn_cfgs=dict(\n                    embed_dims=1024,\n                    feedforward_channels=4096,\n                    num_fcs=2,\n                    act_cfg=dict(type='ReLU', inplace=True),\n                    ffn_drop=0.0,\n                    dropout_layer=None,\n                    add_identity=True,\n                    with_cp=True),\n                feedforward_channels=4096,\n                operation_order=('cross_attn', 'norm', 'self_attn', 'norm',\n                                 'ffn', 'norm')),\n            init_cfg=None),\n        loss_cls=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=False,\n            loss_weight=2.0,\n            reduction='mean',\n            class_weight=[\n                1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n                1.0, 1.0, 1.0, 1.0, 0.1\n            ]),\n        loss_mask=dict(\n            type='CrossEntropyLoss',\n            use_sigmoid=True,\n            reduction='mean',\n            loss_weight=5.0),\n        loss_dice=dict(\n            type='DiceLoss',\n            use_sigmoid=True,\n            activate=True,\n            reduction='mean',\n            naive_dice=True,\n            eps=1.0,\n            loss_weight=5.0),\n        train_cfg=dict(\n            num_points=12544,\n            oversample_ratio=3.0,\n            importance_sample_ratio=0.75,\n            assigner=dict(\n                type='MaskHungarianAssigner',\n                cls_cost=dict(type='ClassificationCost', weight=2.0),\n                mask_cost=dict(\n                    type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n                dice_cost=dict(\n                    type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n            sampler=dict(type='MaskPseudoSampler')),\n        test_cfg=dict(\n            panoptic_on=True,\n            semantic_on=False,\n            instance_on=True,\n            max_per_image=100,\n            iou_thr=0.8,\n            filter_low_score=True,\n            mode='slide',\n            crop_size=(896, 896),\n            stride=(512, 512))),\n    train_cfg=dict(\n        num_points=12544,\n        oversample_ratio=3.0,\n        importance_sample_ratio=0.75,\n        assigner=dict(\n            type='MaskHungarianAssigner',\n            cls_cost=dict(type='ClassificationCost', weight=2.0),\n            mask_cost=dict(\n                type='CrossEntropyLossCost', weight=5.0, use_sigmoid=True),\n            dice_cost=dict(\n                type='DiceCost', weight=5.0, pred_act=True, eps=1.0)),\n        sampler=dict(type='MaskPseudoSampler')),\n    test_cfg=dict(\n        panoptic_on=True,\n        semantic_on=False,\n        instance_on=True,\n        max_per_image=100,\n        iou_thr=0.8,\n        filter_low_score=True,\n        mode='slide',\n        crop_size=(896, 896),\n        stride=(512, 512)),\n    init_cfg=None)\ndataset_type = 'MyDataset'\ndata_root = '/root/autodl-tmp/data'\nimg_norm_cfg = dict(\n    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\ncrop_size = (896, 896)\ntrain_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(type='LoadAnnotations'),\n    dict(type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n    dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),\n    dict(type='RandomFlip', prob=0.5),\n    dict(type='PhotoMetricDistortion'),\n    dict(\n        type='Normalize',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        to_rgb=True),\n    dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),\n    dict(type='ToMask'),\n    dict(type='DefaultFormatBundle'),\n    dict(\n        type='Collect',\n        keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile'),\n    dict(\n        type='MultiScaleFlipAug',\n        img_scale=(2048, 1024),\n        img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n        flip=True,\n        transforms=[\n            dict(\n                type='SETR_Resize',\n                keep_ratio=True,\n                crop_size=(896, 896),\n                setr_multi_scale=True),\n            dict(type='RandomFlip'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='ImageToTensor', keys=['img']),\n            dict(type='Collect', keys=['img'])\n        ])\n]\ndata = dict(\n    samples_per_gpu=2,\n    workers_per_gpu=1,\n    train=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/train',\n        ann_dir='annotations/train',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(type='LoadAnnotations'),\n            dict(\n                type='Resize', img_scale=(2048, 1024), ratio_range=(0.5, 2.0)),\n            dict(type='RandomCrop', crop_size=(896, 896), cat_max_ratio=0.75),\n            dict(type='RandomFlip', prob=0.5),\n            dict(type='PhotoMetricDistortion'),\n            dict(\n                type='Normalize',\n                mean=[123.675, 116.28, 103.53],\n                std=[58.395, 57.12, 57.375],\n                to_rgb=True),\n            dict(type='Pad', size=(896, 896), pad_val=0, seg_pad_val=255),\n            dict(type='ToMask'),\n            dict(type='DefaultFormatBundle'),\n            dict(\n                type='Collect',\n                keys=['img', 'gt_semantic_seg', 'gt_masks', 'gt_labels'])\n        ]),\n    val=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/val',\n        ann_dir='annotations/val',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2048, 1024),\n                img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n                flip=True,\n                transforms=[\n                    dict(\n                        type='SETR_Resize',\n                        keep_ratio=True,\n                        crop_size=(896, 896),\n                        setr_multi_scale=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]),\n    test=dict(\n        type='MyDataset',\n        data_root='/root/autodl-tmp/data',\n        img_dir='images/val',\n        ann_dir='annotations/val',\n        pipeline=[\n            dict(type='LoadImageFromFile'),\n            dict(\n                type='MultiScaleFlipAug',\n                img_scale=(2048, 1024),\n                img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0],\n                flip=True,\n                transforms=[\n                    dict(\n                        type='SETR_Resize',\n                        keep_ratio=True,\n                        crop_size=(896, 896),\n                        setr_multi_scale=True),\n                    dict(type='RandomFlip'),\n                    dict(\n                        type='Normalize',\n                        mean=[123.675, 116.28, 103.53],\n                        std=[58.395, 57.12, 57.375],\n                        to_rgb=True),\n                    dict(type='ImageToTensor', keys=['img']),\n                    dict(type='Collect', keys=['img'])\n                ])\n        ]))\nlog_config = dict(\n    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\ndist_params = dict(backend='nccl')\nlog_level = 'INFO'\nload_from = 'work_dirs/my_city/latest.pth'\nresume_from = None\nworkflow = [('train', 1)]\ncudnn_benchmark = True\noptimizer = dict(\n    type='AdamW',\n    lr=2e-05,\n    betas=(0.9, 0.999),\n    weight_decay=0.05,\n    constructor='LayerDecayOptimizerConstructor',\n    paramwise_cfg=dict(num_layers=24, layer_decay_rate=0.9))\noptimizer_config = dict()\nlr_config = dict(\n    policy='poly',\n    warmup='linear',\n    warmup_iters=1500,\n    warmup_ratio=1e-06,\n    power=1.0,\n    min_lr=0.0,\n    by_epoch=False)\nrunner = dict(type='IterBasedRunner', max_iters=80000)\ncheckpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)\nevaluation = dict(\n    interval=1000, metric='mIoU', pre_eval=True, save_best='mIoU')\npretrained = 'pretrained/beit_large_patch16_224_pt22k_ft22k.pth'\nwork_dir = './work_dirs/my_city'\ngpu_ids = range(0, 1)\nauto_resume = False\nseed = 613560434\n", "CLASSES": ["WATER", "ASPHALT", "GRASS", "HUMAN", "ANIMAL", "HIGH_VEGETATION", "GROUND_VEHICLE", "FACADE", "WIRE", "GARDEN_FURNITURE", "CONCRETE", "ROOF", "GRAVEL", "SOIL", "PRIMEAIR_PATTERN", "SNOW"], "PALETTE": [[148, 218, 255], [85, 85, 85], [200, 219, 190], [166, 133, 226], [255, 171, 225], [40, 150, 114], [234, 144, 133], [89, 82, 96], [255, 255, 0], [110, 87, 121], [205, 201, 195], [212, 80, 121], [159, 135, 114], [102, 90, 72], [255, 255, 102], [251, 247, 240]], "hook_msgs": {}}
{"mode": "train", "epoch": 1, "iter": 50, "lr": 0.0, "memory": 31494, "data_time": 0.0367, "decode.loss_cls": 0.63422, "decode.loss_mask": 0.85223, "decode.loss_dice": 1.44892, "decode.d0.loss_cls": 5.68417, "decode.d0.loss_mask": 0.85895, "decode.d0.loss_dice": 1.60232, "decode.d1.loss_cls": 0.59787, "decode.d1.loss_mask": 0.85223, "decode.d1.loss_dice": 1.53347, "decode.d2.loss_cls": 0.59384, "decode.d2.loss_mask": 0.84719, "decode.d2.loss_dice": 1.48779, "decode.d3.loss_cls": 0.6242, "decode.d3.loss_mask": 0.84919, "decode.d3.loss_dice": 1.43279, "decode.d4.loss_cls": 0.6595, "decode.d4.loss_mask": 0.84279, "decode.d4.loss_dice": 1.42294, "decode.d5.loss_cls": 0.62077, "decode.d5.loss_mask": 0.86033, "decode.d5.loss_dice": 1.44945, "decode.d6.loss_cls": 0.62789, "decode.d6.loss_mask": 0.83947, "decode.d6.loss_dice": 1.44237, "decode.d7.loss_cls": 0.627, "decode.d7.loss_mask": 0.84718, "decode.d7.loss_dice": 1.44961, "decode.d8.loss_cls": 0.61103, "decode.d8.loss_mask": 0.86825, "decode.d8.loss_dice": 1.45903, "loss": 34.52698, "time": 2.86569}
{"mode": "train", "epoch": 1, "iter": 100, "lr": 0.0, "memory": 31494, "data_time": 0.02072, "decode.loss_cls": 0.52596, "decode.loss_mask": 0.80884, "decode.loss_dice": 1.317, "decode.d0.loss_cls": 5.72363, "decode.d0.loss_mask": 0.86712, "decode.d0.loss_dice": 1.46197, "decode.d1.loss_cls": 0.57964, "decode.d1.loss_mask": 0.8396, "decode.d1.loss_dice": 1.40462, "decode.d2.loss_cls": 0.56256, "decode.d2.loss_mask": 0.83064, "decode.d2.loss_dice": 1.35034, "decode.d3.loss_cls": 0.58609, "decode.d3.loss_mask": 0.8367, "decode.d3.loss_dice": 1.30606, "decode.d4.loss_cls": 0.56631, "decode.d4.loss_mask": 0.82677, "decode.d4.loss_dice": 1.30875, "decode.d5.loss_cls": 0.53004, "decode.d5.loss_mask": 0.83454, "decode.d5.loss_dice": 1.30681, "decode.d6.loss_cls": 0.53863, "decode.d6.loss_mask": 0.81265, "decode.d6.loss_dice": 1.31639, "decode.d7.loss_cls": 0.50425, "decode.d7.loss_mask": 0.81601, "decode.d7.loss_dice": 1.33118, "decode.d8.loss_cls": 0.53935, "decode.d8.loss_mask": 0.80763, "decode.d8.loss_dice": 1.31864, "loss": 32.3587, "time": 2.74674}
{"mode": "train", "epoch": 1, "iter": 150, "lr": 0.0, "memory": 31494, "data_time": 0.02191, "decode.loss_cls": 0.61128, "decode.loss_mask": 0.73275, "decode.loss_dice": 1.27346, "decode.d0.loss_cls": 5.72782, "decode.d0.loss_mask": 0.77631, "decode.d0.loss_dice": 1.45805, "decode.d1.loss_cls": 0.67302, "decode.d1.loss_mask": 0.74811, "decode.d1.loss_dice": 1.37305, "decode.d2.loss_cls": 0.61457, "decode.d2.loss_mask": 0.73202, "decode.d2.loss_dice": 1.33139, "decode.d3.loss_cls": 0.6368, "decode.d3.loss_mask": 0.74037, "decode.d3.loss_dice": 1.29342, "decode.d4.loss_cls": 0.66851, "decode.d4.loss_mask": 0.7261, "decode.d4.loss_dice": 1.27929, "decode.d5.loss_cls": 0.61248, "decode.d5.loss_mask": 0.73564, "decode.d5.loss_dice": 1.29298, "decode.d6.loss_cls": 0.63196, "decode.d6.loss_mask": 0.72491, "decode.d6.loss_dice": 1.29244, "decode.d7.loss_cls": 0.60929, "decode.d7.loss_mask": 0.7258, "decode.d7.loss_dice": 1.29992, "decode.d8.loss_cls": 0.59178, "decode.d8.loss_mask": 0.73443, "decode.d8.loss_dice": 1.29883, "loss": 31.94678, "time": 2.75579}
{"mode": "train", "epoch": 1, "iter": 200, "lr": 0.0, "memory": 31494, "data_time": 0.0224, "decode.loss_cls": 0.54232, "decode.loss_mask": 0.80247, "decode.loss_dice": 1.37009, "decode.d0.loss_cls": 5.67484, "decode.d0.loss_mask": 0.84886, "decode.d0.loss_dice": 1.52042, "decode.d1.loss_cls": 0.61624, "decode.d1.loss_mask": 0.82879, "decode.d1.loss_dice": 1.46216, "decode.d2.loss_cls": 0.56925, "decode.d2.loss_mask": 0.7959, "decode.d2.loss_dice": 1.40405, "decode.d3.loss_cls": 0.57904, "decode.d3.loss_mask": 0.80239, "decode.d3.loss_dice": 1.37567, "decode.d4.loss_cls": 0.54432, "decode.d4.loss_mask": 0.79941, "decode.d4.loss_dice": 1.37319, "decode.d5.loss_cls": 0.5553, "decode.d5.loss_mask": 0.79949, "decode.d5.loss_dice": 1.39022, "decode.d6.loss_cls": 0.53886, "decode.d6.loss_mask": 0.80114, "decode.d6.loss_dice": 1.37051, "decode.d7.loss_cls": 0.55511, "decode.d7.loss_mask": 0.80651, "decode.d7.loss_dice": 1.38067, "decode.d8.loss_cls": 0.5302, "decode.d8.loss_mask": 0.80003, "decode.d8.loss_dice": 1.39123, "loss": 32.82866, "time": 2.7517}
{"mode": "train", "epoch": 1, "iter": 250, "lr": 0.0, "memory": 31494, "data_time": 0.02252, "decode.loss_cls": 0.62418, "decode.loss_mask": 0.79724, "decode.loss_dice": 1.40433, "decode.d0.loss_cls": 5.67685, "decode.d0.loss_mask": 0.88707, "decode.d0.loss_dice": 1.60531, "decode.d1.loss_cls": 0.58901, "decode.d1.loss_mask": 0.82395, "decode.d1.loss_dice": 1.50346, "decode.d2.loss_cls": 0.63529, "decode.d2.loss_mask": 0.79576, "decode.d2.loss_dice": 1.4365, "decode.d3.loss_cls": 0.6194, "decode.d3.loss_mask": 0.79737, "decode.d3.loss_dice": 1.39908, "decode.d4.loss_cls": 0.61409, "decode.d4.loss_mask": 0.79902, "decode.d4.loss_dice": 1.40651, "decode.d5.loss_cls": 0.6224, "decode.d5.loss_mask": 0.80133, "decode.d5.loss_dice": 1.40705, "decode.d6.loss_cls": 0.60855, "decode.d6.loss_mask": 0.80347, "decode.d6.loss_dice": 1.41063, "decode.d7.loss_cls": 0.58802, "decode.d7.loss_mask": 0.80283, "decode.d7.loss_dice": 1.40938, "decode.d8.loss_cls": 0.57852, "decode.d8.loss_mask": 0.8034, "decode.d8.loss_dice": 1.40424, "loss": 33.65425, "time": 2.75033}
{"mode": "train", "epoch": 1, "iter": 300, "lr": 0.0, "memory": 31494, "data_time": 0.02166, "decode.loss_cls": 0.61147, "decode.loss_mask": 0.81369, "decode.loss_dice": 1.4527, "decode.d0.loss_cls": 5.65066, "decode.d0.loss_mask": 0.83627, "decode.d0.loss_dice": 1.61127, "decode.d1.loss_cls": 0.58898, "decode.d1.loss_mask": 0.84014, "decode.d1.loss_dice": 1.56036, "decode.d2.loss_cls": 0.56238, "decode.d2.loss_mask": 0.82073, "decode.d2.loss_dice": 1.50844, "decode.d3.loss_cls": 0.59501, "decode.d3.loss_mask": 0.82495, "decode.d3.loss_dice": 1.46705, "decode.d4.loss_cls": 0.58312, "decode.d4.loss_mask": 0.82012, "decode.d4.loss_dice": 1.46797, "decode.d5.loss_cls": 0.60226, "decode.d5.loss_mask": 0.80084, "decode.d5.loss_dice": 1.45738, "decode.d6.loss_cls": 0.61492, "decode.d6.loss_mask": 0.80264, "decode.d6.loss_dice": 1.44372, "decode.d7.loss_cls": 0.60409, "decode.d7.loss_mask": 0.80892, "decode.d7.loss_dice": 1.43971, "decode.d8.loss_cls": 0.61513, "decode.d8.loss_mask": 0.81124, "decode.d8.loss_dice": 1.44514, "loss": 34.06131, "time": 2.7486}
{"mode": "train", "epoch": 1, "iter": 350, "lr": 0.0, "memory": 31494, "data_time": 0.02163, "decode.loss_cls": 0.52382, "decode.loss_mask": 0.77289, "decode.loss_dice": 1.25993, "decode.d0.loss_cls": 5.67134, "decode.d0.loss_mask": 0.81788, "decode.d0.loss_dice": 1.36279, "decode.d1.loss_cls": 0.54094, "decode.d1.loss_mask": 0.78708, "decode.d1.loss_dice": 1.31054, "decode.d2.loss_cls": 0.52513, "decode.d2.loss_mask": 0.78113, "decode.d2.loss_dice": 1.26332, "decode.d3.loss_cls": 0.52871, "decode.d3.loss_mask": 0.7725, "decode.d3.loss_dice": 1.23737, "decode.d4.loss_cls": 0.53381, "decode.d4.loss_mask": 0.7752, "decode.d4.loss_dice": 1.23937, "decode.d5.loss_cls": 0.53419, "decode.d5.loss_mask": 0.76457, "decode.d5.loss_dice": 1.24758, "decode.d6.loss_cls": 0.52933, "decode.d6.loss_mask": 0.76603, "decode.d6.loss_dice": 1.24697, "decode.d7.loss_cls": 0.4928, "decode.d7.loss_mask": 0.76776, "decode.d7.loss_dice": 1.24871, "decode.d8.loss_cls": 0.50373, "decode.d8.loss_mask": 0.75533, "decode.d8.loss_dice": 1.23936, "loss": 30.80013, "time": 2.7538}
{"mode": "train", "epoch": 1, "iter": 400, "lr": 0.0, "memory": 31494, "data_time": 0.0214, "decode.loss_cls": 0.54827, "decode.loss_mask": 0.77588, "decode.loss_dice": 1.31081, "decode.d0.loss_cls": 5.64802, "decode.d0.loss_mask": 0.8236, "decode.d0.loss_dice": 1.4944, "decode.d1.loss_cls": 0.59453, "decode.d1.loss_mask": 0.79397, "decode.d1.loss_dice": 1.39993, "decode.d2.loss_cls": 0.56739, "decode.d2.loss_mask": 0.77288, "decode.d2.loss_dice": 1.3458, "decode.d3.loss_cls": 0.60015, "decode.d3.loss_mask": 0.76921, "decode.d3.loss_dice": 1.30954, "decode.d4.loss_cls": 0.57458, "decode.d4.loss_mask": 0.77187, "decode.d4.loss_dice": 1.31263, "decode.d5.loss_cls": 0.57084, "decode.d5.loss_mask": 0.7744, "decode.d5.loss_dice": 1.30866, "decode.d6.loss_cls": 0.57696, "decode.d6.loss_mask": 0.7717, "decode.d6.loss_dice": 1.29811, "decode.d7.loss_cls": 0.546, "decode.d7.loss_mask": 0.77343, "decode.d7.loss_dice": 1.29685, "decode.d8.loss_cls": 0.52676, "decode.d8.loss_mask": 0.76837, "decode.d8.loss_dice": 1.31751, "loss": 31.94302, "time": 2.74651}
{"mode": "train", "epoch": 1, "iter": 450, "lr": 0.0, "memory": 31494, "data_time": 0.02099, "decode.loss_cls": 0.55984, "decode.loss_mask": 0.78333, "decode.loss_dice": 1.32953, "decode.d0.loss_cls": 5.62218, "decode.d0.loss_mask": 0.78972, "decode.d0.loss_dice": 1.50702, "decode.d1.loss_cls": 0.51566, "decode.d1.loss_mask": 0.83226, "decode.d1.loss_dice": 1.45, "decode.d2.loss_cls": 0.55087, "decode.d2.loss_mask": 0.76977, "decode.d2.loss_dice": 1.35045, "decode.d3.loss_cls": 0.53244, "decode.d3.loss_mask": 0.76706, "decode.d3.loss_dice": 1.33676, "decode.d4.loss_cls": 0.51879, "decode.d4.loss_mask": 0.77527, "decode.d4.loss_dice": 1.35113, "decode.d5.loss_cls": 0.51731, "decode.d5.loss_mask": 0.76764, "decode.d5.loss_dice": 1.35475, "decode.d6.loss_cls": 0.5481, "decode.d6.loss_mask": 0.77199, "decode.d6.loss_dice": 1.32969, "decode.d7.loss_cls": 0.5275, "decode.d7.loss_mask": 0.77676, "decode.d7.loss_dice": 1.33175, "decode.d8.loss_cls": 0.53062, "decode.d8.loss_mask": 0.78132, "decode.d8.loss_dice": 1.3336, "loss": 31.91311, "time": 2.75459}
{"mode": "train", "epoch": 1, "iter": 500, "lr": 0.0, "memory": 31494, "data_time": 0.02324, "decode.loss_cls": 0.55862, "decode.loss_mask": 0.76555, "decode.loss_dice": 1.31572, "decode.d0.loss_cls": 5.60807, "decode.d0.loss_mask": 0.79183, "decode.d0.loss_dice": 1.45415, "decode.d1.loss_cls": 0.54812, "decode.d1.loss_mask": 0.78874, "decode.d1.loss_dice": 1.43457, "decode.d2.loss_cls": 0.54698, "decode.d2.loss_mask": 0.77448, "decode.d2.loss_dice": 1.36457, "decode.d3.loss_cls": 0.57893, "decode.d3.loss_mask": 0.77313, "decode.d3.loss_dice": 1.34569, "decode.d4.loss_cls": 0.5544, "decode.d4.loss_mask": 0.7598, "decode.d4.loss_dice": 1.33952, "decode.d5.loss_cls": 0.55959, "decode.d5.loss_mask": 0.76366, "decode.d5.loss_dice": 1.33449, "decode.d6.loss_cls": 0.54383, "decode.d6.loss_mask": 0.76161, "decode.d6.loss_dice": 1.32557, "decode.d7.loss_cls": 0.54462, "decode.d7.loss_mask": 0.7713, "decode.d7.loss_dice": 1.33534, "decode.d8.loss_cls": 0.56572, "decode.d8.loss_mask": 0.75944, "decode.d8.loss_dice": 1.34145, "loss": 31.90951, "time": 2.75499}
{"mode": "train", "epoch": 1, "iter": 550, "lr": 0.0, "memory": 31494, "data_time": 0.02351, "decode.loss_cls": 0.51761, "decode.loss_mask": 0.73129, "decode.loss_dice": 1.32185, "decode.d0.loss_cls": 5.59032, "decode.d0.loss_mask": 0.74062, "decode.d0.loss_dice": 1.44937, "decode.d1.loss_cls": 0.51473, "decode.d1.loss_mask": 0.74312, "decode.d1.loss_dice": 1.42414, "decode.d2.loss_cls": 0.49136, "decode.d2.loss_mask": 0.72848, "decode.d2.loss_dice": 1.35956, "decode.d3.loss_cls": 0.51985, "decode.d3.loss_mask": 0.7173, "decode.d3.loss_dice": 1.32772, "decode.d4.loss_cls": 0.52315, "decode.d4.loss_mask": 0.72116, "decode.d4.loss_dice": 1.32297, "decode.d5.loss_cls": 0.52378, "decode.d5.loss_mask": 0.72656, "decode.d5.loss_dice": 1.31484, "decode.d6.loss_cls": 0.53839, "decode.d6.loss_mask": 0.73086, "decode.d6.loss_dice": 1.30254, "decode.d7.loss_cls": 0.48477, "decode.d7.loss_mask": 0.74374, "decode.d7.loss_dice": 1.34104, "decode.d8.loss_cls": 0.51285, "decode.d8.loss_mask": 0.7316, "decode.d8.loss_dice": 1.34476, "loss": 31.04032, "time": 2.75731}
{"mode": "train", "epoch": 1, "iter": 600, "lr": 0.0, "memory": 31494, "data_time": 0.02311, "decode.loss_cls": 0.57722, "decode.loss_mask": 0.75815, "decode.loss_dice": 1.41308, "decode.d0.loss_cls": 5.5818, "decode.d0.loss_mask": 0.81683, "decode.d0.loss_dice": 1.58603, "decode.d1.loss_cls": 0.62103, "decode.d1.loss_mask": 0.78862, "decode.d1.loss_dice": 1.48808, "decode.d2.loss_cls": 0.58794, "decode.d2.loss_mask": 0.76718, "decode.d2.loss_dice": 1.43957, "decode.d3.loss_cls": 0.62264, "decode.d3.loss_mask": 0.7526, "decode.d3.loss_dice": 1.39371, "decode.d4.loss_cls": 0.58823, "decode.d4.loss_mask": 0.76015, "decode.d4.loss_dice": 1.38911, "decode.d5.loss_cls": 0.57608, "decode.d5.loss_mask": 0.75739, "decode.d5.loss_dice": 1.40036, "decode.d6.loss_cls": 0.58245, "decode.d6.loss_mask": 0.75673, "decode.d6.loss_dice": 1.39082, "decode.d7.loss_cls": 0.57628, "decode.d7.loss_mask": 0.75164, "decode.d7.loss_dice": 1.41902, "decode.d8.loss_cls": 0.57274, "decode.d8.loss_mask": 0.76347, "decode.d8.loss_dice": 1.39627, "loss": 32.87523, "time": 2.76228}
{"mode": "train", "epoch": 1, "iter": 650, "lr": 0.0, "memory": 31494, "data_time": 0.02183, "decode.loss_cls": 0.56578, "decode.loss_mask": 0.7666, "decode.loss_dice": 1.27565, "decode.d0.loss_cls": 5.5479, "decode.d0.loss_mask": 0.77537, "decode.d0.loss_dice": 1.41932, "decode.d1.loss_cls": 0.56105, "decode.d1.loss_mask": 0.79902, "decode.d1.loss_dice": 1.35858, "decode.d2.loss_cls": 0.53033, "decode.d2.loss_mask": 0.77497, "decode.d2.loss_dice": 1.30487, "decode.d3.loss_cls": 0.56246, "decode.d3.loss_mask": 0.76746, "decode.d3.loss_dice": 1.28082, "decode.d4.loss_cls": 0.56476, "decode.d4.loss_mask": 0.76637, "decode.d4.loss_dice": 1.2771, "decode.d5.loss_cls": 0.55991, "decode.d5.loss_mask": 0.77351, "decode.d5.loss_dice": 1.27519, "decode.d6.loss_cls": 0.56476, "decode.d6.loss_mask": 0.7629, "decode.d6.loss_dice": 1.28084, "decode.d7.loss_cls": 0.55626, "decode.d7.loss_mask": 0.76096, "decode.d7.loss_dice": 1.28304, "decode.d8.loss_cls": 0.56314, "decode.d8.loss_mask": 0.76205, "decode.d8.loss_dice": 1.2858, "loss": 31.32678, "time": 2.75472}
{"mode": "train", "epoch": 1, "iter": 700, "lr": 0.0, "memory": 31494, "data_time": 0.02125, "decode.loss_cls": 0.51938, "decode.loss_mask": 0.76725, "decode.loss_dice": 1.3198, "decode.d0.loss_cls": 5.56612, "decode.d0.loss_mask": 0.79569, "decode.d0.loss_dice": 1.43465, "decode.d1.loss_cls": 0.50252, "decode.d1.loss_mask": 0.79625, "decode.d1.loss_dice": 1.4067, "decode.d2.loss_cls": 0.49466, "decode.d2.loss_mask": 0.78022, "decode.d2.loss_dice": 1.35035, "decode.d3.loss_cls": 0.51419, "decode.d3.loss_mask": 0.78408, "decode.d3.loss_dice": 1.33316, "decode.d4.loss_cls": 0.53774, "decode.d4.loss_mask": 0.77956, "decode.d4.loss_dice": 1.30525, "decode.d5.loss_cls": 0.49983, "decode.d5.loss_mask": 0.79459, "decode.d5.loss_dice": 1.31582, "decode.d6.loss_cls": 0.49812, "decode.d6.loss_mask": 0.77841, "decode.d6.loss_dice": 1.32504, "decode.d7.loss_cls": 0.52258, "decode.d7.loss_mask": 0.76552, "decode.d7.loss_dice": 1.32691, "decode.d8.loss_cls": 0.52221, "decode.d8.loss_mask": 0.76349, "decode.d8.loss_dice": 1.3217, "loss": 31.42181, "time": 2.75281}
{"mode": "train", "epoch": 2, "iter": 750, "lr": 0.0, "memory": 31494, "data_time": 0.07065, "decode.loss_cls": 0.59715, "decode.loss_mask": 0.81009, "decode.loss_dice": 1.42605, "decode.d0.loss_cls": 5.50944, "decode.d0.loss_mask": 0.83779, "decode.d0.loss_dice": 1.58561, "decode.d1.loss_cls": 0.6277, "decode.d1.loss_mask": 0.8229, "decode.d1.loss_dice": 1.53685, "decode.d2.loss_cls": 0.61845, "decode.d2.loss_mask": 0.81077, "decode.d2.loss_dice": 1.46383, "decode.d3.loss_cls": 0.64122, "decode.d3.loss_mask": 0.79667, "decode.d3.loss_dice": 1.42904, "decode.d4.loss_cls": 0.6275, "decode.d4.loss_mask": 0.80724, "decode.d4.loss_dice": 1.42501, "decode.d5.loss_cls": 0.64311, "decode.d5.loss_mask": 0.79706, "decode.d5.loss_dice": 1.43105, "decode.d6.loss_cls": 0.59908, "decode.d6.loss_mask": 0.80075, "decode.d6.loss_dice": 1.41651, "decode.d7.loss_cls": 0.58142, "decode.d7.loss_mask": 0.80903, "decode.d7.loss_dice": 1.42288, "decode.d8.loss_cls": 0.61377, "decode.d8.loss_mask": 0.81165, "decode.d8.loss_dice": 1.4224, "loss": 33.722, "time": 2.80861}
{"mode": "train", "epoch": 2, "iter": 800, "lr": 0.0, "memory": 31494, "data_time": 0.02512, "decode.loss_cls": 0.48495, "decode.loss_mask": 0.75403, "decode.loss_dice": 1.30396, "decode.d0.loss_cls": 5.51451, "decode.d0.loss_mask": 0.79107, "decode.d0.loss_dice": 1.43888, "decode.d1.loss_cls": 0.48548, "decode.d1.loss_mask": 0.76358, "decode.d1.loss_dice": 1.40005, "decode.d2.loss_cls": 0.50385, "decode.d2.loss_mask": 0.75383, "decode.d2.loss_dice": 1.34876, "decode.d3.loss_cls": 0.50036, "decode.d3.loss_mask": 0.75032, "decode.d3.loss_dice": 1.31856, "decode.d4.loss_cls": 0.50997, "decode.d4.loss_mask": 0.75552, "decode.d4.loss_dice": 1.31566, "decode.d5.loss_cls": 0.4726, "decode.d5.loss_mask": 0.75801, "decode.d5.loss_dice": 1.31833, "decode.d6.loss_cls": 0.48358, "decode.d6.loss_mask": 0.7632, "decode.d6.loss_dice": 1.31022, "decode.d7.loss_cls": 0.47946, "decode.d7.loss_mask": 0.76135, "decode.d7.loss_dice": 1.32299, "decode.d8.loss_cls": 0.4955, "decode.d8.loss_mask": 0.76145, "decode.d8.loss_dice": 1.30197, "loss": 30.92199, "time": 2.85768}
{"mode": "train", "epoch": 2, "iter": 850, "lr": 0.0, "memory": 31494, "data_time": 0.02565, "decode.loss_cls": 0.56508, "decode.loss_mask": 0.75855, "decode.loss_dice": 1.31745, "decode.d0.loss_cls": 5.46381, "decode.d0.loss_mask": 0.77265, "decode.d0.loss_dice": 1.49127, "decode.d1.loss_cls": 0.54076, "decode.d1.loss_mask": 0.78329, "decode.d1.loss_dice": 1.45144, "decode.d2.loss_cls": 0.53038, "decode.d2.loss_mask": 0.75743, "decode.d2.loss_dice": 1.38185, "decode.d3.loss_cls": 0.57227, "decode.d3.loss_mask": 0.74808, "decode.d3.loss_dice": 1.32902, "decode.d4.loss_cls": 0.57199, "decode.d4.loss_mask": 0.75592, "decode.d4.loss_dice": 1.3432, "decode.d5.loss_cls": 0.55858, "decode.d5.loss_mask": 0.7655, "decode.d5.loss_dice": 1.34436, "decode.d6.loss_cls": 0.59012, "decode.d6.loss_mask": 0.76024, "decode.d6.loss_dice": 1.31427, "decode.d7.loss_cls": 0.60579, "decode.d7.loss_mask": 0.7549, "decode.d7.loss_dice": 1.32632, "decode.d8.loss_cls": 0.5593, "decode.d8.loss_mask": 0.75473, "decode.d8.loss_dice": 1.32526, "loss": 31.79381, "time": 3.12712}
{"mode": "train", "epoch": 2, "iter": 900, "lr": 0.0, "memory": 31494, "data_time": 0.02236, "decode.loss_cls": 0.46215, "decode.loss_mask": 0.78647, "decode.loss_dice": 1.22656, "decode.d0.loss_cls": 5.45179, "decode.d0.loss_mask": 0.81829, "decode.d0.loss_dice": 1.33521, "decode.d1.loss_cls": 0.43814, "decode.d1.loss_mask": 0.79952, "decode.d1.loss_dice": 1.31312, "decode.d2.loss_cls": 0.43536, "decode.d2.loss_mask": 0.79372, "decode.d2.loss_dice": 1.2702, "decode.d3.loss_cls": 0.45991, "decode.d3.loss_mask": 0.79605, "decode.d3.loss_dice": 1.2394, "decode.d4.loss_cls": 0.46457, "decode.d4.loss_mask": 0.79196, "decode.d4.loss_dice": 1.23929, "decode.d5.loss_cls": 0.44224, "decode.d5.loss_mask": 0.79011, "decode.d5.loss_dice": 1.24046, "decode.d6.loss_cls": 0.46047, "decode.d6.loss_mask": 0.79286, "decode.d6.loss_dice": 1.22834, "decode.d7.loss_cls": 0.44611, "decode.d7.loss_mask": 0.79849, "decode.d7.loss_dice": 1.25149, "decode.d8.loss_cls": 0.47832, "decode.d8.loss_mask": 0.79721, "decode.d8.loss_dice": 1.24606, "loss": 30.09387, "time": 2.88357}
{"mode": "train", "epoch": 2, "iter": 950, "lr": 0.0, "memory": 31494, "data_time": 0.02835, "decode.loss_cls": 0.52111, "decode.loss_mask": 0.76746, "decode.loss_dice": 1.30209, "decode.d0.loss_cls": 5.38863, "decode.d0.loss_mask": 0.80298, "decode.d0.loss_dice": 1.40057, "decode.d1.loss_cls": 0.47024, "decode.d1.loss_mask": 0.80363, "decode.d1.loss_dice": 1.3992, "decode.d2.loss_cls": 0.50621, "decode.d2.loss_mask": 0.7881, "decode.d2.loss_dice": 1.33682, "decode.d3.loss_cls": 0.51577, "decode.d3.loss_mask": 0.78101, "decode.d3.loss_dice": 1.30534, "decode.d4.loss_cls": 0.52528, "decode.d4.loss_mask": 0.77765, "decode.d4.loss_dice": 1.30557, "decode.d5.loss_cls": 0.51994, "decode.d5.loss_mask": 0.77937, "decode.d5.loss_dice": 1.32226, "decode.d6.loss_cls": 0.50239, "decode.d6.loss_mask": 0.77754, "decode.d6.loss_dice": 1.30938, "decode.d7.loss_cls": 0.50133, "decode.d7.loss_mask": 0.77416, "decode.d7.loss_dice": 1.32275, "decode.d8.loss_cls": 0.48793, "decode.d8.loss_mask": 0.77149, "decode.d8.loss_dice": 1.31019, "loss": 31.0764, "time": 3.13148}
{"mode": "train", "epoch": 2, "iter": 1000, "lr": 0.0, "memory": 31494, "data_time": 0.02439, "decode.loss_cls": 0.54595, "decode.loss_mask": 0.74623, "decode.loss_dice": 1.3323, "decode.d0.loss_cls": 5.38015, "decode.d0.loss_mask": 0.7781, "decode.d0.loss_dice": 1.47331, "decode.d1.loss_cls": 0.56561, "decode.d1.loss_mask": 0.77094, "decode.d1.loss_dice": 1.42559, "decode.d2.loss_cls": 0.5372, "decode.d2.loss_mask": 0.75457, "decode.d2.loss_dice": 1.38089, "decode.d3.loss_cls": 0.57834, "decode.d3.loss_mask": 0.75455, "decode.d3.loss_dice": 1.3434, "decode.d4.loss_cls": 0.58162, "decode.d4.loss_mask": 0.73719, "decode.d4.loss_dice": 1.33541, "decode.d5.loss_cls": 0.53921, "decode.d5.loss_mask": 0.74409, "decode.d5.loss_dice": 1.33229, "decode.d6.loss_cls": 0.57294, "decode.d6.loss_mask": 0.74668, "decode.d6.loss_dice": 1.33102, "decode.d7.loss_cls": 0.55038, "decode.d7.loss_mask": 0.75272, "decode.d7.loss_dice": 1.33087, "decode.d8.loss_cls": 0.5427, "decode.d8.loss_mask": 0.75585, "decode.d8.loss_dice": 1.34492, "loss": 31.56503, "time": 3.23466}
